---
title: "Exploratory DVs"
author: "Zeynep Enkavi"
output: 
html_document:
toc: true
toc_depts: 2
---

```{r setup_env, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(GGally)
library(plyr)
library(dplyr)
library(tidyr)
sem<-function(x)sd(x, na.rm=T)/sqrt(length(x[!is.na(x)]))
```

# Exploratory DVs

Since I am currently unable to successfully recover parameters on simulated data as described above here are some exploratory dependent variables that might capture the question of interest more simply.

To take a step back, this sample consists of three age groups: kids, teens and adults and we hypothesize that the increase in risk taking behavior with age is related to sensitivity to high variance feedback. 

Had I been able to fit the models correctly, the parameter of interest to observe the age differences on would have been an exponent on the prediction errors (as Sarah fit them or on rewards as we may have fitted them).

Here are some exploratory thoughts on other ways to quantify how sensitive subjects are to feedback from different machines.

```{r read_in_data, echo=FALSE, data_read_in}
##################
#Machine game data
##################
file_list <- list.files("/Users/zeynepenkavi/Downloads/machine_game")

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/machine_game/",file))
  tmp$Sub_id <- as.numeric(gsub("[^0-9]", "", file))
  tmp$Trial_number <- 1:nrow(tmp)
  
  if('X' %in% names(tmp)){
    tmp <- tmp[,-which(names(tmp) == "X")]
  }
  
  if (file == file_list[1]){
    machine_game_data = tmp
  }
  else{
    machine_game_data = rbind(machine_game_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)

#Remove subjects with incomplete data
incomplete_subs <- as.numeric(names(which(table(machine_game_data$Sub_id)!=180)))

machine_game_data_clean <- machine_game_data[machine_game_data$Sub_id %in% incomplete_subs == F,]

rm(incomplete_subs)

#Add cols for machine properties
assign.machine.info <- function(data){
  data$facet_labels <- with(data, ifelse(Trial_type == 1, "+5,-495", ifelse(Trial_type == 2, "-5,+495", ifelse(Trial_type == 3, "-10,+100", ifelse(Trial_type == 4, "+10,-100", NA)))))
  
  data$gain_mag <- with(data, ifelse(Trial_type == 1, "5", ifelse(Trial_type == 2, "495", ifelse(Trial_type == 3, "100", ifelse(Trial_type == 4, "10", NA)))))
  
  data$loss_mag <- with(data, ifelse(Trial_type == 1, "495", ifelse(Trial_type == 2, "5", ifelse(Trial_type == 3, "10", ifelse(Trial_type == 4, "100", NA)))))
  
  data$gain_freq <- with(data, ifelse(Trial_type == 1, "90", ifelse(Trial_type == 2, "10", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$loss_freq <-  with(data, ifelse(Trial_type == 1, "10", ifelse(Trial_type == 2, "90", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$magnitude <- with(data, ifelse(Trial_type == 1, "large", ifelse(Trial_type == 2, "large", ifelse(Trial_type == 3, "small", ifelse(Trial_type == 4, "small", NA)))))
  
  data$variance <- with(data, ifelse(Trial_type == 1, "high", ifelse(Trial_type == 2, "high", ifelse(Trial_type == 3, "low", ifelse(Trial_type == 4, "low", NA)))))
  
  return(data)
}

machine_game_data_clean <- assign.machine.info(machine_game_data_clean)


##################
#Demographics data
##################
demog_data <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/Developmental study/Final Redcap Data/DevelopmentalStudy_DATA_2015-03-25_1258.csv')

# head(names(demog_data), 20)
# str(demog_data$subj_id)
# str(demog_data$calc_age)

# Add age data to machine_game_data_clean
assign.age.info <- function(data){
  
  data$age_group <- with(data, ifelse(Sub_id<200000, "kid", ifelse(Sub_id>200000 & Sub_id<300000, "teen", "adult")))
  
  data %>%
    group_by(Sub_id) %>%
    left_join(demog_data[,c('subj_id', 'calc_age')], by = c("Sub_id" = "subj_id"))
}

machine_game_data_clean <- assign.age.info(machine_game_data_clean)

# Check if there are any problems with the merged ages
# summary(machine_game_data_clean$calc_age)
# which(is.na(machine_game_data_clean$calc_age))

##########
#Bart data
##########
file_list <- list.files("/Users/zeynepenkavi/Downloads/bart_tsv", pattern = '*.tsv')

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/bart_tsv/",file), sep = "\t")
  tmp$Sub_id <- as.numeric(strsplit(file, "_")[[1]][1])
  
  if (file == file_list[1]){
    bart_data = tmp
  }
  else{
    bart_data = rbind(bart_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)
```

## Sample info

First let's get a sense of the sample. Here is how many subjects we have who have complete datasets for the probabilistic learning task and their age break downs.

```{r sample_info, warning=FALSE}
machine_game_data_clean %>% 
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group) %>%
  summarise(min_age = min(calc_age),
            mean_age = mean(calc_age),
            sd_age = sd(calc_age),
            max_age = max(calc_age),
            n = n()/180)
```

## Proportion of playing

The first thing we can look at is how often do subjects play versus pass. It seems that teens play most frequently while adults play least frequently.

```{r}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(age_group, Response) %>%
  tally %>%
  group_by(age_group) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  ggplot(aes(Response, pct, fill = age_group))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  theme_bw()+
  ylab('Percentage of trials')
```

We can break this down by machines.

```{r warning=FALSE}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, facet_labels, Response) %>%
  summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  theme_bw()+
  ylab('Percentage of trials')+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')
```

Are these differences in frequency of playing significant? A hierarchical regression suggests that compared to adults kids play more frequently in the '+5,-495' condition and less frequently in the '-10,+100' condition. (Teens are not different from adults.)

In other words kids are more sensitive to small but frequent losses and less sensitive to large but infrequent losses compared to adults.

So they update the expected value of e.g. the high variance negative EV slower compared to adults (which would have translated to an exponent <1 on the prediction error had the model fitting worked); they are less sensitive to the magnitude of change in the prediction error (and more affected by frequency of feedback). (*Is this interpretation correct?*)

```{r}
tmp <- machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  filter(Response == 'play') %>%
  do(assign.age.info(.))

summary(lmerTest::lmer(pct ~ age_group*facet_labels + (1|Sub_id), data = tmp))
rm(tmp)
```

Let's consider the optimal action for each machine: To maximize rewards one must always play the positive expected value machines and never play the negative expected value machines. So this underweighing of large magnitudes and overweighing of frequency of losses results in kids behaving more suboptimally compared to adults (though note that adults are also pretty far from 0 or 100 in playing any machine). I need to think about whether these two have dissociable roles. I'm not sure contrasting which machines would answer this because the variance and magnitude are perfectly correlated in the experimental setup. 

One data point that I thought might be helpful was to compare the decrease in playing between low variance positive EV to low variance negative EV (-10, +100 vs +10,-100) with the decrease in playing between low variance positive EV and high variance negative EV (-10, +100 vs +5, -495). Since playing is lower in general for +10,-100 it seems that everyone is more sensitive to the frequency of losses than their magnitude and the decrease in adult's playing proportion is even larger than the kids'. It seems that kids are not more sensitive to the frequency of losses compared to adults either. It does also seem to be the case that between the magnitude and frequency they change their behavior more based on the frequency than the magnitude. But it's not clear to me whether their suboptimal behavior in the +5,-495 condition compared to adults is due to kids' lack of sensitivity to the magnitude of change or whether they learn better from more frequent feedback (i.e. a comparative overweighing of frequency of change) since these two change together in the experiment.

Percentage of time playing each machine gives us a sense of the global behavior but we are probably looking for a finer measure that would tell us more about how the behavior of a single subject changes from trial to trial (that we could also use parametrically for imaging analyses). 

Without any advanced models a simple statistic that we can calculate to capture change in behavior depending on the observed outcome is to count how many trials it takes a subject to play a machine again.  

## Average number of trials to play again post outcome

If subjects are sensitive to losses and learning something about the machines in a way that overweights their most recent experience with the machine (e.g. a simple prediction error model that had been used for this data before) one sanity check is to compare how many trials it takes subjects to play a machine again after a loss versus a gain. Presumably the former would be higher than the latter.

```{r func_def, warning=FALSE}
count.postoutcome.trials <- function(subject_data){
  
  loss_trials = which(subject_data$Points_earned<0)
  
  gain_trials = which(subject_data$Points_earned>0)
  
  play_trials= which(subject_data$Response == 1)
  
  post_loss_trials = play_trials[which(play_trials %in% loss_trials)+1]
  
  post_gain_trials = play_trials[which(play_trials %in% gain_trials)+1]
  
  num_trials_post_loss = post_loss_trials - loss_trials
  
  num_trials_post_gain = post_gain_trials - gain_trials
  
  if(length(num_trials_post_gain)>length(num_trials_post_loss)){
    num_trials_post_loss <- c(num_trials_post_loss, rep(NA, length(num_trials_post_gain) - length(num_trials_post_loss)))
  }
  else if(length(num_trials_post_gain)<length(num_trials_post_loss)){
    num_trials_post_gain <- c(num_trials_post_gain, rep(NA, length(num_trials_post_loss) - length(num_trials_post_gain)))
  }
  
  return(data.frame(num_trials_post_loss = num_trials_post_loss, num_trials_post_gain = num_trials_post_gain))
}

# subject_data <- machine_game_data_clean[1:180,]
# tmp <- count.postoutcome.trials(subject_data)
```

This graph shows the average number of trials it takes a subject to play a given machine after experiencing a loss or a gain. For almost everyone and for every machine the average number of trials it takes a subject to play following a loss is higher than the average number of trials it take them to play following a gain. This suggests that subjects are responding to outcomes in a way overweights their most recent experience with the machine [[because if they were taking all their experiences with the machine in to account then would we have expected there to be no difference in the low variance machines. or does this suggest they learn more from losses than gains]] [[how does this statement depend on frequency of gain/loss??]] 

```{r}
machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  do(assign.age.info(.)) %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  gather(key, value, -Sub_id, -facet_labels) %>%
  ggplot(aes(factor(Sub_id), value, color=key))+
  geom_point()+
  theme_bw()+
  facet_wrap(~facet_labels)+
  scale_x_discrete(labels=NULL)+
  xlab('Subjects')
```

This histogram suggests that ignoring which machine the loss is experienced on and which machine they play on next it takes subjects between 1-2 trials to play again after a loss. 

This seems to suggest that behavior almost doesn't change at all after a loss and that is (hopefully) unlikely to be true. So let's look at how many trials it takes a subject to play again on each machine after experiencing a loss on that machine.

```{r warning=FALSE}


machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  do(assign.age.info(.)) %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  group_by(facet_labels) %>%
  summarise(mean_post_loss = mean(mean_post_loss, na.rm=T),
            mean_post_gain = mean(mean_post_gain, na.rm=T))
  

machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  do(assign.age.info(.)) %>%
  select(Sub_id, facet_labels, num_trials_post_loss, num_trials_post_gain) %>%
  gather(key, value, -Sub_id, -facet_labels) %>%
  ggplot(aes(value, fill=key))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~facet_labels)


postloss_trials <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~Trial_type)) %>%
  do(count.postloss.trials(.))  %>%
  do(assign.machine.info(.)) %>%
  do(assign.age.info(.))

mean_postloss_trials <- postloss_trials %>%
  group_by(Sub_id) %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T))

mean_postloss_trials %>% ggplot(aes(mean_post_loss))+
  geom_histogram()+
  theme_bw()
```

It looks like it takes subjects fewer trials to play a machine again for machines with smaller losses compared to larger losses. For larger losses they are also faster to play it again if the losses are less frequent.

```{r warning=FALSE}
mean_postloss_trials_per_machine <- postloss_trials %>%
  group_by_(.dots = list(~Sub_id, ~Trial_type)) %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T)) %>%
  do(assign.machine.info(.)) %>%
  do(assign.age.info(.))

mean_postloss_trials_per_machine %>% ggplot(aes(mean_post_loss))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~facet_labels)

mean_postloss_trials_per_machine %>% ggplot(aes(calc_age,mean_post_loss))+
  geom_point()+
  geom_smooth() +
  theme_bw()+
  facet_wrap(~facet_labels)

mean_postloss_trials_per_machine %>% 
  #transmute(age_group = factor(age_group, levels = c('kid', 'teen', 'adult')))%>%
  group_by_(.dots = list(~age_group, ~facet_labels)) %>%
  summarise(age_group_mean = mean(mean_post_loss, na.rm=T),
            age_group_sem = sem(mean_post_loss)) %>%
  ggplot(aes(factor(age_group, levels = c('kid', 'teen', 'adult')),age_group_mean))+
  geom_bar(stat = 'identity', position = position_dodge(width=0.9))+
  geom_errorbar(aes(ymin = age_group_mean - age_group_sem, ymax = age_group_mean + age_group_sem), position = position_dodge(width=0.9), width =0.25)+
  theme_bw()+
  facet_wrap(~facet_labels)+
  xlab('')+
  ylab('Average number of trials after loss to play again')

mean_postloss_trials_per_machine %>% 
  group_by(facet_labels) %>%
  summarise(mean=mean(mean_post_loss, na.rm=T), sd = sd(mean_post_loss, na.rm=T))
```

Let's check if these distributions are different from one another with a paired t-test.

It seems that only the first panel is significantly different than the others. That is, subjects are faster to play the machine when they experience small losses half of the time compared to the other machines. 

```{r warning=FALSE}
with(mean_postloss_trials_per_machine, pairwise.t.test(mean_post_loss, facet_labels, p.adjust.method = 'bonferroni', paired=T))
```

What we are interested in is whether there is an age difference in each of these panels, or even more specifically whether there is an age difference in the last panel and whether this correlates with risk taking behavior (i.e. BART).

```{r warning=FALSE}
```


```{r}
#Does this correlate with age or bart adjusted pumps? No.

adjusted.pumps <- function(subject_data){
  subject_data_adjusted = subject_data[subject_data$exploded == 0,]
  subject_pumps <- subject_data_adjusted %>% 
    group_by(trial.num) %>%
    summarise(total_pumps = sum(finished))
  out <- data.frame(Sub_id = unique(subject_data$Sub_id), mean_adjusted_pumps = mean(subject_pumps$total_pumps))
  return(out)
}

#subject_data <- bart_data[c(bart_data$Sub_id == 100003),]
#adjusted.pumps(subject_data)

bart_pumps <- ddply(bart_data, .(Sub_id), adjusted.pumps)

mean_postloss_trials <- merge(mean_postloss_trials, bart_pumps, all.x = T, by= 'Sub_id')

ggpairs(mean_postloss_trials, (which(names(mean_postloss_trials) %in% c('calc_age', 'mean_post_loss', 'mean_adjusted_pumps'))))
```

The average number of trials it takes you play a machine again after a loss is 'contaminated' with your memory for it. A closely related measure that could get around memory effects (though they might be of interest since they are presumably necessary for learning) and capture a 'purer' reaction to loss is to check how the probability of playing immediately after a loss trial differs between the groups.
Do we have any theories on how this should behave throughout the task if you are learning something about the machines?


## Mean p(play) post loss
Operationalized as: Number of times you played immediately after experiencing a loss/Number of loss trials

```{r}
mean.postloss.play.prob <- function(subject_data){
  
  Sub_id = unique(subject_data$Sub_id)
  
  loss_trials = which(subject_data$Points_earned<0)
  
  mean_post_loss_prob <- mean(ifelse(subject_data$Response[loss_trials+1] == 2, 1, 0), na.rm=T)
  
  out <- data.frame(Sub_id = Sub_id, mean_post_loss_prob = mean_post_loss_prob)
  
  return(out)
}

# subject_data <- machine_game_data_clean[1:180,]
#tmp <- mean.postloss.play.prob(subject_data)

mean_postloss_trials <- merge(mean_postloss_trials, ddply(machine_game_data_clean, .(Sub_id), mean.postloss.play.prob), all.x=T, by='Sub_id')

ggpairs(mean_postloss_trials, (which(names(mean_postloss_trials) %in% c('calc_age', 'mean_post_loss', 'mean_adjusted_pumps', 'mean_post_loss_prob'))))
```

## How many people experience multiple losses (for each machine)

```{r}
loss.per.machine <- function(subject_data){
  
  Sub_id = unique(subject_data$Sub_id)
  
  loss_trials = which(subject_data$Points_earned<0)
  
  loss_per_machine = as.data.frame(table(subject_data$Trial_type[loss_trials]))
  
  out <- data.frame(Sub_id = rep(Sub_id, nrow(loss_per_machine)), machine = loss_per_machine$Var1, num_loss = loss_per_machine$Freq)
  
  return(out)
}

#subject_data <- machine_game_data_clean[1:180,]
#tmp <- loss.per.machine(subject_data)

loss_per_machine <- ddply(machine_game_data_clean, .(Sub_id), loss.per.machine)

loss_per_machine$facet_labels <- with(loss_per_machine, ifelse(machine == 1, "+5,-495", ifelse(machine == 2, "-5,+495", ifelse(machine == 3, "-10,+100", ifelse(machine == 4, "+10,-100", NA)))))

head(loss_per_machine)

loss_per_machine %>%
  ggplot(aes(num_loss))+
  geom_histogram()+
  facet_wrap(~facet_labels)+
  theme_bw()

#With machine do people experience a single loss most frequently?
with(loss_per_machine[loss_per_machine$num_loss == 1,], table(facet_labels))
```

## Cross-talk between machines
are you less likely to play overall after a loss or only less likely to play that machine

```{r}
mean_postloss_play_prob_per_machine <- ddply(machine_game_data_clean, .(Sub_id, Trial_type), mean.postloss.play.prob)

mean_postloss_play_prob_per_machine$facet_labels <- with(mean_postloss_play_prob_per_machine, ifelse(Trial_type == 1, "+5,-495", ifelse(Trial_type == 2, "-5,+495", ifelse(Trial_type == 3, "-10,+100", ifelse(Trial_type == 4, "+10,-100", NA)))))

mean_postloss_play_prob_per_machine %>% ggplot(aes(mean_post_loss_prob, fill = facet_labels))+
  geom_histogram(alpha = 0.5)+
  theme_bw()#+
#facet_wrap(~facet_labels)

mean_postloss_trials%>% ggplot(aes(mean_post_loss_prob))+
  geom_histogram()+
  theme_bw()

tmp <- mean_postloss_trials[,c("Sub_id", "mean_post_loss_prob")]
tmp$Trial_type <- 0
tmp$facet_labels <- 'Overall'
tmp <- tmp[,c(3,1,2,4)]
tmp <- rbind(tmp, mean_postloss_play_prob_per_machine)

tmp %>% ggplot(aes(mean_post_loss_prob, fill = facet_labels))+
  geom_histogram(alpha=0.5)+
  theme_bw()


pairwise.t.test(tmp$mean_post_loss_prob, tmp$facet_labels)

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='-10,+100'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='+10,-100'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='-5,+495'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='+5,-495'])

#Less likely to play after a loss trial in the low varince positive EV machine and more likely to play after a loss trial in the low variance positive EV machine

#What is optimal here? Is this pattern 'rational'?
#I don't think so. In the positive EV machine the optimal thing would be to always play. The decrease in probability in playing (from 0.5) after experiencing small losses would lead one to make less than one could
#Conversely in the low variance negative expected value machine one should never play. But the increase in probability in playing after losses 
```
