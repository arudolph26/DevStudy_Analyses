---
title: "Exploratory DVs"
author: "Zeynep Enkavi"
output: 
html_document:
toc: true
toc_depts: 2
---

```{r setup_env, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(GGally)
library(plyr)
library(dplyr)
library(tidyr)
sem<-function(x)sd(x, na.rm=T)/sqrt(length(x[!is.na(x)]))
```

# Exploratory DVs

Since I am currently unable to successfully recover parameters on simulated data as described above here are some exploratory dependent variables that might capture the question of interest more simply.

To take a step back, this sample consists of three age groups: kids, teens and adults and we hypothesize that the increase in risk taking behavior with age is related to sensitivity to high variance feedback. 

Had I been able to fit the models correctly, the parameter of interest to observe the age differences on would have been an exponent on the prediction errors (as Sarah fit them or on rewards as we may have fitted them).

Here are some exploratory thoughts on other ways to quantify how sensitive subjects are to feedback from different machines.

```{r read_in_data, echo=FALSE, data_read_in}
##################
#Machine game data
##################
file_list <- list.files("/Users/zeynepenkavi/Downloads/machine_game")

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/machine_game/",file))
  tmp$Sub_id <- as.numeric(gsub("[^0-9]", "", file))
  tmp$Trial_number <- 1:nrow(tmp)
  
  if('X' %in% names(tmp)){
    tmp <- tmp[,-which(names(tmp) == "X")]
  }
  
  if (file == file_list[1]){
    machine_game_data = tmp
  }
  else{
    machine_game_data = rbind(machine_game_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)

#Remove subjects with incomplete data
incomplete_subs <- as.numeric(names(which(table(machine_game_data$Sub_id)!=180)))

machine_game_data_clean <- machine_game_data[machine_game_data$Sub_id %in% incomplete_subs == F,]

rm(incomplete_subs)

#Add cols for machine properties
assign.machine.info <- function(data){
  data$facet_labels <- with(data, ifelse(Trial_type == 1, "+5,-495", ifelse(Trial_type == 2, "-5,+495", ifelse(Trial_type == 3, "-10,+100", ifelse(Trial_type == 4, "+10,-100", NA)))))
  
  data$gain_mag <- with(data, ifelse(Trial_type == 1, "5", ifelse(Trial_type == 2, "495", ifelse(Trial_type == 3, "100", ifelse(Trial_type == 4, "10", NA)))))
  
  data$loss_mag <- with(data, ifelse(Trial_type == 1, "495", ifelse(Trial_type == 2, "5", ifelse(Trial_type == 3, "10", ifelse(Trial_type == 4, "100", NA)))))
  
  data$gain_freq <- with(data, ifelse(Trial_type == 1, "90", ifelse(Trial_type == 2, "10", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$loss_freq <-  with(data, ifelse(Trial_type == 1, "10", ifelse(Trial_type == 2, "90", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$magnitude <- with(data, ifelse(Trial_type == 1, "large", ifelse(Trial_type == 2, "large", ifelse(Trial_type == 3, "small", ifelse(Trial_type == 4, "small", NA)))))
  
  data$variance <- with(data, ifelse(Trial_type == 1, "high", ifelse(Trial_type == 2, "high", ifelse(Trial_type == 3, "low", ifelse(Trial_type == 4, "low", NA)))))
  
  return(data)
}

machine_game_data_clean <- assign.machine.info(machine_game_data_clean)


##################
#Demographics data
##################
demog_data <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/Developmental study/Final Redcap Data/DevelopmentalStudy_DATA_2015-03-25_1258.csv')

# head(names(demog_data), 20)
# str(demog_data$subj_id)
# str(demog_data$calc_age)

# Add age data to machine_game_data_clean
assign.age.info <- function(data){
  
  data$age_group <- with(data, ifelse(Sub_id<200000, "kid", ifelse(Sub_id>200000 & Sub_id<300000, "teen", "adult")))
  
  data %>%
    group_by(Sub_id) %>%
    left_join(demog_data[,c('subj_id', 'calc_age')], by = c("Sub_id" = "subj_id"))
}

machine_game_data_clean <- assign.age.info(machine_game_data_clean)

# Check if there are any problems with the merged ages
# summary(machine_game_data_clean$calc_age)
# which(is.na(machine_game_data_clean$calc_age))

##########
#Bart data
##########
file_list <- list.files("/Users/zeynepenkavi/Downloads/bart_tsv", pattern = '*.tsv')

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/bart_tsv/",file), sep = "\t")
  tmp$Sub_id <- as.numeric(strsplit(file, "_")[[1]][1])
  
  if (file == file_list[1]){
    bart_data = tmp
  }
  else{
    bart_data = rbind(bart_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)
```

## Sample info

First let's get a sense of the sample. Here is how many subjects we have who have complete datasets for the probabilistic learning task and their age break downs.

```{r sample_info, warning=FALSE}
machine_game_data_clean %>% 
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group) %>%
  summarise(min_age = min(calc_age),
            mean_age = mean(calc_age),
            sd_age = sd(calc_age),
            max_age = max(calc_age),
            n = n()/180)
```

## Proportion of playing

The first thing we can look at is how often do subjects play versus pass. It seems that teens and kids play more frequently while adults play least frequently.

This is somewhat counterintuitive and confusing given the assumption in our hypothesis that adults take more risks and therefore perform better in this task. Any increase in 'risk-taking' in this task with age should depend on the machine and its expected value to translate to better performance.

```{r}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(age_group, Response) %>%
  tally %>%
  group_by(age_group) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  ggplot(aes(Response, pct, fill = age_group))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  theme_bw()+
  ylab('Percentage of trials')
```

To get a better sense of risk attitudes in different contingency states we break this proportion of playing down by machines.

Indeed now we can see that adults are more 'risk-taking' i.e. play more frequently in positive expected value machines and less likely to play in negative expected value machines. This is why they perform better overall.

```{r warning=FALSE}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, facet_labels, Response) %>%
  summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  theme_bw()+
  ylab('Percentage of trials')+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')
```

Speaking of performances let's take a quick look at the number of points subjects end up with at the end of the task.

Indeed adults earn more points in the low variance positive expected value machine (though not significantly in the positive expected value high variance machine) and loose less points in the negative expected value machines. These are hard to read off of the interactions in the hierarchical regression (I think) because most of the variance is explained by the difference between conditions but analyses of simple effects looking at age effects within each condition confirms the pattern seen on the plot.

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group, facet_labels) %>%
  summarise(mean_points = mean(total_points),
            sem_points = sem(total_points)) %>%
  ggplot(aes(facet_labels, mean_points, fill=age_group))+
  geom_bar(stat='identity', position = position_dodge((0.9)))+
  geom_errorbar(aes(ymin=mean_points-sem_points, ymax=mean_points+sem_points), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('Machine')+
  ylab('Mean points')+
  labs(fill='Age group')


tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))%>%
summary(lmerTest::lmer(total_points ~ age_group*facet_labels + (1|Sub_id), data = tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))%>%
  filter(facet_labels=='+10,-100')
summary(lm(total_points ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))%>%
  filter(facet_labels=='-5,+495')
summary(lm(total_points ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))%>%
  filter(facet_labels=='+10,-100')
summary(lm(total_points ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))%>%
  filter(facet_labels=='+5,-495')
summary(lm(total_points ~ age_group, data=tmp))
rm(tmp)
```

Going back to task behavior: Are these differences in frequency of playing significant? A hierarchical regression suggests that compared to adults kids play more frequently in the '+5,-495' condition and less frequently in the '-10,+100' condition. (Teens are not different from adults.)

In other words kids are more sensitive to small but frequent losses and less sensitive to large but infrequent losses compared to adults.

So they update the expected value of e.g. the high variance negative machine slower compared to adults (which would have translated to an exponent <1 on the prediction error had the model fitting worked); they are less sensitive to the magnitude of change in the prediction error (and more affected by frequency of feedback). (*Is this interpretation correct?*)

```{r}
tmp <- machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  filter(Response == 'play') %>%
  do(assign.age.info(.))

summary(lmerTest::lmer(pct ~ age_group*facet_labels + (1|Sub_id), data = tmp))
rm(tmp)
```

Let's consider the optimal action for each machine for a minute: To maximize rewards one must always play the positive expected value machines and never play the negative expected value machines. So this underweighing of large magnitudes and overweighing of frequency of losses results in kids behaving more suboptimally compared to adults (though note that adults are also pretty far from 0 or 100 in playing any machine). I need to think about whether these two (sensitivity to magnitude versus to frequency) have dissociable roles. I'm not sure contrasting which machines would answer this because the variance and magnitude are perfectly correlated in the experimental setup. 

One data point that I thought might be helpful was to compare the decrease in playing between low variance positive EV to low variance negative EV (-10, +100 vs +10,-100) with the decrease in playing between low variance positive EV and high variance negative EV (-10, +100 vs +5, -495). Since playing is lower in general for +10,-100 it seems that everyone is more sensitive to the frequency of losses than their magnitude and the decrease in adult's playing proportion is even larger than the kids'. It seems that kids are not more sensitive to the frequency of losses compared to adults either (as I may have implied above). It does, however, also seem to be the case that between the magnitude and frequency they change their behavior more based on the frequency than the magnitude. But it's not clear to me whether their suboptimal behavior in the +5,-495 condition compared to adults is due to kids' lack of sensitivity to the magnitude of change or whether they learn better from more frequent feedback (i.e. a comparative overweighing of frequency of change) since these two change together in the experiment.

Since I'm not sure how to resolve this for now let's move on to other exploratory DVs. Percentage of time playing each machine gives us a sense of the global behavior but we are probably looking for a finer measure that would tell us more about how the behavior of a single subject changes from trial to trial (that we could also use parametrically for imaging analyses) depending on their observations. 

Without any advanced models a simple statistic that we can calculate to capture change in behavior depending on the observed outcome is to count how many trials it takes a subject to play a machine again.  

## Average number of trials to play again post outcome

If subjects are sensitive to losses and learning something about the machines in a way that overweights their most recent experience with the machine (e.g. a simple prediction error model that had been used for this data before) one sanity check is to compare how many trials it takes subjects to play a machine again after a loss versus a gain. Presumably the former would be higher than the latter, that is one would hesitate to play a machine again after a loss but more likely to play it after a gain.

```{r func_def, warning=FALSE}
count.postoutcome.trials <- function(subject_data){
  
  loss_trials = which(subject_data$Points_earned<0)
  
  gain_trials = which(subject_data$Points_earned>0)
  
  play_trials= which(subject_data$Response == 1)
  
  post_loss_trials = play_trials[which(play_trials %in% loss_trials)+1]
  
  post_gain_trials = play_trials[which(play_trials %in% gain_trials)+1]
  
  num_trials_post_loss = post_loss_trials - loss_trials
  
  num_trials_post_gain = post_gain_trials - gain_trials
  
  if(length(num_trials_post_gain)>length(num_trials_post_loss)){
    num_trials_post_loss <- c(num_trials_post_loss, rep(NA, length(num_trials_post_gain) - length(num_trials_post_loss)))
  }
  else if(length(num_trials_post_gain)<length(num_trials_post_loss)){
    num_trials_post_gain <- c(num_trials_post_gain, rep(NA, length(num_trials_post_loss) - length(num_trials_post_gain)))
  }
  
  return(data.frame(num_trials_post_loss = num_trials_post_loss, num_trials_post_gain = num_trials_post_gain))
}

# subject_data <- machine_game_data_clean[1:180,]
# tmp <- count.postoutcome.trials(subject_data)
```

This graph shows the average number of trials it takes a subject to play a given machine after experiencing a loss or a gain. For almost everyone and for every machine the average number of trials it takes a subject to play following a loss (red dot) is higher than the average number of trials it take them to play following a gain (blue dot). This suggests that subjects are responding to outcomes in a way overweights their most recent experience with the machine. I think this serves as a (weak) sanity check for our intuitions modeling this data using simple prediction error models that are updated after each trial.

One thought that is not necessarily immediately pertinent but that I puzzled over is how this graph would have looked like if subjects were taking all their experiences with the machine in to account (instead of overweighing their most recent experience). I have a vague intuition that in that case the difference in responding between the experiences (gain/loss) would be 0. That is, if one takes in to account all their experiences then they would distinguish between the positive and negative EV machines and either always play for positive EV machines or never play for negative EV machines regardless of the observed outcome. Relatedly then, this difference in response patterns depending on the observed outcome could be due to at least two reasons: memory or loss aversion. Or perhaps stronger memories for losses. I'm not sure where I'm going with this but perhaps there is something interesting to look at in the hippocampal activity following losses versus gains.

```{r}
machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  do(assign.age.info(.)) %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  gather(key, value, -Sub_id, -facet_labels) %>%
  ggplot(aes(factor(Sub_id), value, color=factor(key, levels = c("mean_post_loss", "mean_post_gain"))))+
  geom_point()+
  theme_bw()+
  facet_wrap(~facet_labels)+
  scale_x_discrete(labels=NULL)+
  xlab('Subjects')+
  labs(color = NULL)
```

As our finer trial-by-trial measure, however, we have hypothesized that the driver of age differences would lie in post loss behavior. The previous plot also supports this strategy since there is less variability in post gain behavior (blue dots) compared to the post loss behavior. So let's see if there are age difference in post loss behavior.

Indeed, reflecting the global behavior in proportion of playing in each condition adults are less likely to play after large losses in the high variance negative EV condition compared to kids while kids are less sensitive to the magnitude of loss. This, however is only a marginal effect based on the simple effects below and there aren't other significant age differences in other conditions.

```{r}
machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group, facet_labels) %>%
  summarise(sem_post_loss = sem(mean_post_loss),
            mean_post_loss = mean(mean_post_loss, na.rm=T))%>%
  ggplot(aes(facet_labels, mean_post_loss, fill=age_group)) +
  geom_bar(stat='identity', position=position_dodge(0.9))+
  geom_errorbar(aes(ymin=mean_post_loss-sem_post_loss, ymax=mean_post_loss+sem_post_loss), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('Machine')+
  ylab("Average number of trials post loss")+
  labs(fill='Age group')

tmp <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  filter(facet_labels == '-10,+100')

summary(lm(mean_post_loss ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  filter(facet_labels == '-5,+495')

summary(lm(mean_post_loss ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  filter(facet_labels == '+10,-100')

summary(lm(mean_post_loss ~ age_group, data=tmp))
rm(tmp)

tmp <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  filter(facet_labels == '+5,-495')

summary(lm(mean_post_loss ~ age_group, data=tmp))
rm(tmp)
```

Since we're not finding strong age differences on this potentially still somewhat coarse measure of sensitivity to magnitude of loss and we have some evidence/apriori assumptions built in prediction error models that subjects overweight their most recent experience perhaps a better DV would be the probability that a subject plays after each loss. That is, how often does a subject play immediately after a loss.

```{r}
#What is the probability that you'll play after a loss trial
#The higher this is in the high var negative EV condition the worse your performance
mean.postloss.play.prob <- function(subject_data){
  
  Sub_id = unique(subject_data$Sub_id)
  
  loss_trials = which(subject_data$Points_earned<0)
  
  mean_post_loss_prob <- mean(ifelse(subject_data$Response[loss_trials+1] == 1, 1, 0), na.rm=T)
  
  return(data.frame(mean_post_loss_prob=mean_post_loss_prob))
}

machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  do(mean.postloss.play.prob(.)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group, facet_labels) %>%
  summarise(sem_post_loss_prob = sem(mean_post_loss_prob),
            mean_post_loss_prob = mean(mean_post_loss_prob)) %>%
  ggplot(aes(facet_labels, mean_post_loss_prob, fill=age_group))+
  geom_bar(stat = 'identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin=mean_post_loss_prob - sem_post_loss_prob, ymax=mean_post_loss_prob + sem_post_loss_prob), position=position_dodge(0.9), width=0.25)+
  theme_bw()+
  labs(fill = 'Age group')+
  xlab('Machine')+
  ylab('Mean playing prob post loss trial')
```

-----
Thought of regressing total points on average number of trials after a loss to see if it could explain the performance difference but I think they might be necessarily correlated by definition. ???

```{r}
tmp <- machine_game_data_clean %>%
  group_by_(.dots = list(~Sub_id, ~facet_labels)) %>%
  do(count.postoutcome.trials(.))  %>%
  summarise(mean_post_loss = mean(num_trials_post_loss, na.rm=T),
            mean_post_gain = mean(num_trials_post_gain, na.rm=T)) %>%
  select(Sub_id, facet_labels, mean_post_loss) %>%
  left_join(summarise(group_by(machine_game_data_clean, Sub_id, facet_labels), total_points = sum(Points_earned)), by = c("Sub_id", "facet_labels")) %>%
  do(assign.age.info(.))

summary(lm(total_points ~ age_group*mean_post_loss*facet_labels, data=tmp))
with(tmp, cor.test(total_points, mean_post_loss))
```


```{r}
#Does this correlate with age or bart adjusted pumps? No.

adjusted.pumps <- function(subject_data){
  subject_data_adjusted = subject_data[subject_data$exploded == 0,]
  subject_pumps <- subject_data_adjusted %>% 
    group_by(trial.num) %>%
    summarise(total_pumps = sum(finished))
  out <- data.frame(Sub_id = unique(subject_data$Sub_id), mean_adjusted_pumps = mean(subject_pumps$total_pumps))
  return(out)
}

#subject_data <- bart_data[c(bart_data$Sub_id == 100003),]
#adjusted.pumps(subject_data)

bart_pumps <- ddply(bart_data, .(Sub_id), adjusted.pumps)

mean_postloss_trials <- merge(mean_postloss_trials, bart_pumps, all.x = T, by= 'Sub_id')

ggpairs(mean_postloss_trials, (which(names(mean_postloss_trials) %in% c('calc_age', 'mean_post_loss', 'mean_adjusted_pumps'))))
```

The average number of trials it takes you play a machine again after a loss is 'contaminated' with your memory for it. A closely related measure that could get around memory effects (though they might be of interest since they are presumably necessary for learning) and capture a 'purer' reaction to loss is to check how the probability of playing immediately after a loss trial differs between the groups.
Do we have any theories on how this should behave throughout the task if you are learning something about the machines?


## Mean p(play) post loss
Operationalized as: Number of times you played immediately after experiencing a loss/Number of loss trials

```{r}
mean.postloss.play.prob <- function(subject_data){
  
  Sub_id = unique(subject_data$Sub_id)
  
  loss_trials = which(subject_data$Points_earned<0)
  
  mean_post_loss_prob <- mean(ifelse(subject_data$Response[loss_trials+1] == 2, 1, 0), na.rm=T)
  
  out <- data.frame(Sub_id = Sub_id, mean_post_loss_prob = mean_post_loss_prob)
  
  return(out)
}

# subject_data <- machine_game_data_clean[1:180,]
#tmp <- mean.postloss.play.prob(subject_data)

mean_postloss_trials <- merge(mean_postloss_trials, ddply(machine_game_data_clean, .(Sub_id), mean.postloss.play.prob), all.x=T, by='Sub_id')

ggpairs(mean_postloss_trials, (which(names(mean_postloss_trials) %in% c('calc_age', 'mean_post_loss', 'mean_adjusted_pumps', 'mean_post_loss_prob'))))
```

## How many people experience multiple losses (for each machine)

```{r}
loss.per.machine <- function(subject_data){
  
  Sub_id = unique(subject_data$Sub_id)
  
  loss_trials = which(subject_data$Points_earned<0)
  
  loss_per_machine = as.data.frame(table(subject_data$Trial_type[loss_trials]))
  
  out <- data.frame(Sub_id = rep(Sub_id, nrow(loss_per_machine)), machine = loss_per_machine$Var1, num_loss = loss_per_machine$Freq)
  
  return(out)
}

#subject_data <- machine_game_data_clean[1:180,]
#tmp <- loss.per.machine(subject_data)

loss_per_machine <- ddply(machine_game_data_clean, .(Sub_id), loss.per.machine)

loss_per_machine$facet_labels <- with(loss_per_machine, ifelse(machine == 1, "+5,-495", ifelse(machine == 2, "-5,+495", ifelse(machine == 3, "-10,+100", ifelse(machine == 4, "+10,-100", NA)))))

head(loss_per_machine)

loss_per_machine %>%
  ggplot(aes(num_loss))+
  geom_histogram()+
  facet_wrap(~facet_labels)+
  theme_bw()

#With machine do people experience a single loss most frequently?
with(loss_per_machine[loss_per_machine$num_loss == 1,], table(facet_labels))
```

## Cross-talk between machines
are you less likely to play overall after a loss or only less likely to play that machine

```{r}
mean_postloss_play_prob_per_machine <- ddply(machine_game_data_clean, .(Sub_id, Trial_type), mean.postloss.play.prob)

mean_postloss_play_prob_per_machine$facet_labels <- with(mean_postloss_play_prob_per_machine, ifelse(Trial_type == 1, "+5,-495", ifelse(Trial_type == 2, "-5,+495", ifelse(Trial_type == 3, "-10,+100", ifelse(Trial_type == 4, "+10,-100", NA)))))

mean_postloss_play_prob_per_machine %>% ggplot(aes(mean_post_loss_prob, fill = facet_labels))+
  geom_histogram(alpha = 0.5)+
  theme_bw()#+
#facet_wrap(~facet_labels)

mean_postloss_trials%>% ggplot(aes(mean_post_loss_prob))+
  geom_histogram()+
  theme_bw()

tmp <- mean_postloss_trials[,c("Sub_id", "mean_post_loss_prob")]
tmp$Trial_type <- 0
tmp$facet_labels <- 'Overall'
tmp <- tmp[,c(3,1,2,4)]
tmp <- rbind(tmp, mean_postloss_play_prob_per_machine)

tmp %>% ggplot(aes(mean_post_loss_prob, fill = facet_labels))+
  geom_histogram(alpha=0.5)+
  theme_bw()


pairwise.t.test(tmp$mean_post_loss_prob, tmp$facet_labels)

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='-10,+100'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='+10,-100'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='-5,+495'])

t.test(tmp$mean_post_loss_prob[tmp$facet_labels=='Overall'], tmp$mean_post_loss_prob[tmp$facet_labels=='+5,-495'])

#Less likely to play after a loss trial in the low varince positive EV machine and more likely to play after a loss trial in the low variance positive EV machine

#What is optimal here? Is this pattern 'rational'?
#I don't think so. In the positive EV machine the optimal thing would be to always play. The decrease in probability in playing (from 0.5) after experiencing small losses would lead one to make less than one could
#Conversely in the low variance negative expected value machine one should never play. But the increase in probability in playing after losses 
```
