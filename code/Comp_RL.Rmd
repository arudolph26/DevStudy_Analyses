---
title: "RL models comparison"
output:
github_document:
toc: yes
toc_float: yes
---

```{r}
library(tidyverse)

cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values=cbbPalette) + scale_color_manual(values=cbbPalette)+theme(legend.position="bottom")

input_dir = '/Users/zeynepenkavi/Dropbox/PoldrackLab/DevStudy_Analyses/input/rl_fits/'

fig_path = '/Users/zeynepenkavi/Dropbox/PoldrackLab/DevStudy_Analyses/output/figures/'

sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}

process_fits = function(data){
  require(tidyverse)
  data = data %>% select(-contains("Unnamed"), -contains("X"))
  return(data)
}
```

Save plot of neglogprob distributions for all subject for each model

```{r}
fits = list.files(path=input_dir, pattern = "All")

for(f in fits){
  data = read.csv(paste0(input_dir, f))
  data = process_fits(data)
  p = data %>% 
  ggplot(aes(neglogprob))+
  geom_histogram()+
  facet_wrap(~sub_id, scales='free')
  p_name = gsub('.csv','',f)
  p_name = gsub('LearningParams','Neglogs',p_name)
  ggsave(paste0(p_name, '.jpeg'), plot=p, device = 'jpeg', path = fig_path, width = 30, height = 30, units = "in", limitsize = FALSE)
}
```

Look up df for AIC and BIC calculation

```{r}
num_pars_df = data.frame(model = c('LearningParams_Fit_alpha_Fix_beta-exp_','LearningParams_Fit_alpha_neg_Fix_alpha_pos-beta-exp_','LearningParams_Fit_alpha_neg-alpha_pos_Fix_beta-exp_','LearningParams_Fit_alpha_neg-alpha_pos-beta_Fix_exp_','LearningParams_Fit_alpha_neg-alpha_pos-beta-exp_Fix_','LearningParams_Fit_alpha_neg-alpha_pos-beta-exp_neg_Fix_exp_pos_','LearningParams_Fit_alpha_neg-alpha_pos-beta-exp_neg-exp_pos_Fix_','LearningParams_Fit_alpha_neg-alpha_pos-beta-exp_pos_Fix_exp_neg_','LearningParams_Fit_alpha_neg-alpha_pos-exp_Fix_beta_','LearningParams_Fit_alpha_neg-alpha_pos-exp_neg_Fix_beta-exp_pos_','LearningParams_Fit_alpha_neg-alpha_pos-exp_neg-exp_pos_Fix_beta_','LearningParams_Fit_alpha_neg-alpha_pos-exp_pos_Fix_beta-exp_neg_','LearningParams_Fit_alpha_neg-beta_Fix_alpha_pos-exp_','LearningParams_Fit_alpha_neg-beta-exp_neg_Fix_alpha_pos-exp_pos_','LearningParams_Fit_alpha_neg-beta-exp_pos_Fix_alpha_pos-exp_neg_','LearningParams_Fit_alpha_neg-exp_Fix_alpha_pos-beta_','LearningParams_Fit_alpha_neg-exp_neg_Fix_alpha_pos-beta-exp_pos_','LearningParams_Fit_alpha_neg-exp_neg-exp_pos_Fix_alpha_pos-beta_','LearningParams_Fit_alpha_neg-exp_pos_Fix_alpha_pos-beta-exp_neg_','LearningParams_Fit_alpha_pos_Fix_alpha_neg-beta-exp_','LearningParams_Fit_alpha_pos-beta-exp_Fix_alpha_neg_','LearningParams_Fit_alpha_pos-beta-exp_neg_Fix_alpha_neg-exp_pos_','LearningParams_Fit_alpha_pos-beta-exp_neg-exp_pos_Fix_alpha_neg_','LearningParams_Fit_alpha_pos-beta-exp_pos_Fix_alpha_neg-exp_neg_','LearningParams_Fit_alpha_pos-exp_Fix_alpha_neg-beta_','LearningParams_Fit_alpha_pos-exp_neg_Fix_alpha_neg-beta-exp_pos_','LearningParams_Fit_alpha_pos-exp_neg-exp_pos_Fix_alpha_neg-beta_','LearningParams_Fit_alpha_pos-exp_pos_Fix_alpha_neg-beta-exp_neg_','LearningParams_Fit_alpha-beta-exp_Fix_','LearningParams_Fit_alpha-beta-exp_neg_Fix_exp_pos_','LearningParams_Fit_alpha-beta-exp_neg-exp_pos_Fix_','LearningParams_Fit_alpha-beta-exp_pos_Fix_exp_neg_','LearningParams_Fit_alpha-exp_Fix_beta_','LearningParams_Fit_alpha-exp_neg_Fix_beta-exp_pos_','LearningParams_Fit_alpha-exp_neg-exp_pos_Fix_beta_','LearningParams_Fit_alpha-exp_pos_Fix_beta-exp_neg_','LearningParams_Fit_beta-exp_Fix_alpha_','LearningParams_Fit_beta-exp_neg-exp_pos_Fix_alpha_'), pars = c(1,1,2,3,4,4,5,4,3,3,4,3,2,3,3,2,2,3,2,1,3,3,4,3,2,2,3,2,2,3,4,3,2,2,3,2,2,3))
num_pars_df = num_pars_df %>%
  mutate(model = as.character(model))
```

Which is the best model?

```{r}
out = data.frame(mean_nlp=NA, sem_nlp = NA, mean_aic=NA, sem_aic = NA, mean_bic=NA, sem_bic = NA, model=NA)

for(f in fits){
  data = read.csv(paste0(input_dir, f))
  data = process_fits(data)
  data = data %>%
    group_by(sub_id) %>%
    slice(which.min(neglogprob)) %>%
    select(neglogprob, sub_id, model) %>%
    mutate(model = as.character(model)) %>%
    left_join(num_pars_df, by='model') %>%
    mutate(AIC = 2*neglogprob+2*pars,
           BIC = 2*neglogprob+pars*log(180)) %>%
    ungroup() %>%
    summarise(mean_nlp = mean(neglogprob),
              sem_nlp = sem(neglogprob),
              mean_aic = mean(AIC),
              sem_aic = sem(AIC),
              mean_bic = mean(BIC),
              sem_bic = sem(BIC),
              model = unique(model))
  out = rbind(out, data)
}

out = out %>% drop_na()
```

```{r}
out %>% 
  ggplot(aes(factor(model, levels = out[order(out$mean_nlp),'model']), mean_nlp))+
  geom_point()+
  geom_errorbar(aes(ymin=mean_nlp-sem_nlp, ymax=mean_nlp+sem_nlp))+
  theme(axis.text.x = element_blank())+
  xlab("")+
  ylab("Mean Neglogprob")
```

```{r}
out %>% 
  arrange(mean_nlp) %>%
  select(model, everything())
```

Do models differ in fit by age group?

```{r}

```