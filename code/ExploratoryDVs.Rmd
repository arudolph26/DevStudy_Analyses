---
title: "Developmental changes in sensitivity to high variance feedback relates to differences in risky decision making"
output: 
html_document:
toc: true
toc_depts: 2
---

```{r setup_env, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(GGally)
library(dplyr)
library(tidyr)
library(lme4)
sem<-function(x)sd(x, na.rm=T)/sqrt(length(x[!is.na(x)]))
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values=cbbPalette) + scale_color_manual(values=cbbPalette)+theme(legend.position="bottom")
```

This notebook contains exploratory analyses of behavioral data collected to investigate the relationship between risk taking behavior and probabilistic learning. 

The sample consists of three age groups: kids, teens and adults and we hypothesize that sensitivity to learn from high variance feedback improves with age and this is related to better risky decisions.  

Subjects completed a probabilistic learning task in the scanner, a realistic risky decision making task (BART) outside the scanner and numerous questionnaires. The focus of this notebook is on the first two tasks.  

The plan of analysis is to establish that adults are more sensitive to high variance feedback in the probabilistic learning task and relate this (modeled) sensitivity to behavior in BART.  

```{r echo=FALSE}
##################
#Machine game data
##################
file_list <- list.files("/Users/zeynepenkavi/Downloads/machine_game")

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/machine_game/",file))
  tmp$Sub_id <- as.numeric(gsub("[^0-9]", "", file))
  tmp$Trial_number <- 1:nrow(tmp)
  
  if('X' %in% names(tmp)){
    tmp <- tmp[,-which(names(tmp) == "X")]
  }
  
  if (file == file_list[1]){
    machine_game_data = tmp
  }
  else{
    machine_game_data = rbind(machine_game_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)

#Remove subjects with incomplete data
incomplete_subs <- as.numeric(names(which(table(machine_game_data$Sub_id)!=180)))

machine_game_data_clean <- machine_game_data[machine_game_data$Sub_id %in% incomplete_subs == F,]

rm(incomplete_subs)

#Add cols for machine properties
assign.machine.info <- function(data){
  data$facet_labels <- with(data, ifelse(Trial_type == 1, "+5,-495", ifelse(Trial_type == 2, "-5,+495", ifelse(Trial_type == 3, "-10,+100", ifelse(Trial_type == 4, "+10,-100", NA)))))
  
  data$gain_mag <- with(data, ifelse(Trial_type == 1, "5", ifelse(Trial_type == 2, "495", ifelse(Trial_type == 3, "100", ifelse(Trial_type == 4, "10", NA)))))
  
  data$loss_mag <- with(data, ifelse(Trial_type == 1, "495", ifelse(Trial_type == 2, "5", ifelse(Trial_type == 3, "10", ifelse(Trial_type == 4, "100", NA)))))
  
  data$gain_freq <- with(data, ifelse(Trial_type == 1, "90", ifelse(Trial_type == 2, "10", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$loss_freq <-  with(data, ifelse(Trial_type == 1, "10", ifelse(Trial_type == 2, "90", ifelse(Trial_type == 3, "50", ifelse(Trial_type == 4, "50", NA)))))
  
  data$magnitude <- with(data, ifelse(Trial_type == 1, "large", ifelse(Trial_type == 2, "large", ifelse(Trial_type == 3, "small", ifelse(Trial_type == 4, "small", NA)))))
  
  data$variance <- with(data, ifelse(Trial_type == 1, "high", ifelse(Trial_type == 2, "high", ifelse(Trial_type == 3, "low", ifelse(Trial_type == 4, "low", NA)))))
  
  return(data)
}

machine_game_data_clean <- assign.machine.info(machine_game_data_clean)


##################
#Demographics data
##################
demog_data <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/Sarah_Developmental study/Final Redcap Data/DevelopmentalStudy_DATA_2015-03-25_1258.csv')

# head(names(demog_data), 20)
# str(demog_data$subj_id)
# str(demog_data$calc_age)

# Add age data to machine_game_data_clean
assign.age.info <- function(data){
  
  data$age_group <- with(data, ifelse(Sub_id<200000, "kid", ifelse(Sub_id>200000 & Sub_id<300000, "teen", "adult")))
  
  data %>%
    group_by(Sub_id) %>%
    left_join(demog_data[,c('subj_id', 'calc_age')], by = c("Sub_id" = "subj_id"))
}

machine_game_data_clean <- assign.age.info(machine_game_data_clean)

# Check if there are any problems with the merged ages
# summary(machine_game_data_clean$calc_age)
# which(is.na(machine_game_data_clean$calc_age))

##########
#Bart data
##########
file_list <- list.files("/Users/zeynepenkavi/Downloads/bart_tsv", pattern = '*.tsv')

for (file in file_list){
  
  tmp <- read.csv(paste0("/Users/zeynepenkavi/Downloads/bart_tsv/",file), sep = "\t")
  tmp$Sub_id <- as.numeric(strsplit(file, "_")[[1]][1])
  
  if (file == file_list[1]){
    bart_data = tmp
  }
  else{
    bart_data = rbind(bart_data, tmp)
  }
  rm(tmp)
}

rm(file, file_list)
```

# Sample info

First let's get a sense of the sample. Here is how many subjects we have who have complete datasets for the probabilistic learning task and their age break downs.

```{r sample_info, warning=FALSE}
machine_game_data_clean %>% 
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group) %>%
  summarise(min_age = min(calc_age),
            mean_age = mean(calc_age),
            sd_age = sd(calc_age),
            max_age = max(calc_age),
            n = n()/180)
```

# Performance in probabilistic learning task

We first examine the behavior in the probabilistic learning task.   

In this task subjects are presented with a fractal in each trial. The fractals represent different machines. Subjects choose to play or pass in each trial. Each machine yields a probabilistic reward. There are four machines in total. Two with positive and two with negative expected value. One of each of these machines has a low variance reward schedule while the other has a high variance reward schedule. More clearly:  
- One machine gives \$5 90% of the time and -\$495 %10 of the time  
- One machine gives -\$5 90% of the time and \$495 %10 of the time  
- One machine gives \$10 50% of the time and -$100 %50 of the time  
- One machine gives -\$10 50% of the time and $100 %50 of the time  

## Points earned

Performance in this task can be assessed by looking at the total number of points subjects make at the end of task. The following graph shows that adults collect more points in this task compared to kids.

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group) %>%
  summarise(mean_points = mean(total_points),
            sem_points = sem(total_points)) %>%
  ggplot(aes(age_group, mean_points))+
  geom_bar(stat='identity', position = position_dodge((0.9)))+
  geom_errorbar(aes(ymin=mean_points-sem_points, ymax=mean_points+sem_points), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('Machine')+
  ylab('Mean points')+
  labs(fill='Age group')

```

This difference is statistically significant: adults earn more points compared to the kids (t = 2.771).

```{r}
tmp = machine_game_data_clean %>%
  group_by(Sub_id) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))

summary(lm(total_points~age_group, data=tmp))
```
```{r echo=FALSE}
rm(tmp)
```

Since we are interested in the age differences between sensitivity to different feedback schedules, **we should show that this difference in performance exists especially for the high variance feedback condition(s)**. Here is the plot of performance (total points earned) broken down by conditions.

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult'))) %>%
  group_by(age_group, facet_labels) %>%
  summarise(mean_points = mean(total_points),
            sem_points = sem(total_points)) %>%
  ggplot(aes(facet_labels, mean_points, fill=age_group))+
  geom_bar(stat='identity', position = position_dodge((0.9)))+
  geom_errorbar(aes(ymin=mean_points-sem_points, ymax=mean_points+sem_points), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('Machine')+
  ylab('Mean points')+
  labs(fill='Age group')

```

Running separate models for positive and negative EV machines for ease of interpretation.

```{r}
tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')))
```

In the positive EV machines there is only a main effect of variance. All groups perform better is low variance condition. There are no age differences.

```{r}
summary(lm(total_points ~ age_group*facet_labels, data = tmp %>% filter(facet_labels %in% c("-10,+100", "-5,+495"))))
```

In the negative EV machines there is again the effect of variance: Everyone losses fewer points in the low variance condition. There is also a main effect for adults: Adults perform better than kids for both negative EV machines.

```{r}
summary(lm(total_points ~ age_group*facet_labels, data = tmp %>% filter(facet_labels %in% c("+10,-100", "+5,-495"))))
```

```{r echo=FALSE}
rm(tmp)
```

So the age diffence in performance is driven by difference in performance in negative EV machines. The question is what difference in behavior in these conditions is leading to this difference in performance?  To anticipate possible cognitive processes that will be parameterized in RL models differences can lie in: how quickly the groups learn the probabilities, how much weight they put on the outcomes and/or how much like an optimal agent they behave.

## Proportion of playing

The first thing we can look at is how often do subjects play versus pass. It's hard to see any age differences when we just look at frequency of overall playing as below.   

```{r}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, Response) %>%
  tally %>%
  group_by(Sub_id) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, Response) %>%
  dplyr::summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  theme_bw()+
  ylab('Percentage of trials')+
  labs(fill = 'Age group')
```

It is also not immediately apparent how to translate this to better performance/learning in this task but one way to think about it: If people learned perfectly they should play half of the time (always for the positive expected value trial and never for the negative expected value trials). The fact that all play proportions are above 50% suggests that nobody learns perfectly and that adults might be closest to it. But this is very crude and a better way to look at it would be to see   
1. how this depends on the different machines and   
2. how it changes throughout the task.

To get a better sense of overall behavior in different contingency states we break this proportion of playing down by machines.

Now we can see age differences in playing frequency in different conditions, particularly in the negative expected value machines (bottom row).

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, facet_labels, Response) %>%
  dplyr::summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  theme_bw()+
  ylab('Percentage of trials')+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')
```

The differences in points earned map directly on to proportion of choosing to play each machine:  

- Adults (baseline in the regression below) play most for the low variance positive expected value condition (top left) then significantly less for the high variance positive expected value condition (top right), even less for high variance negative expected value condition (bottom right), and least for the low variance negative expected value condition (bottom left). **This pattern reflects a sensitivity to low variance (better learning for low variance conditions comparing the equivalent expected values).**
- Teens do not differ significantly from adults in any condition.
- Kids do not differ from adults in playing proportion in the positive expected value conditions (top row) but they do choose to play the machine for both of the negative expected value conditions (bottom row)

```{r}
tmp <- machine_game_data_clean %>%
  mutate(age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass'))) %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct_play=(100*n)/sum(n)) %>%
  filter(Response == 'play') %>%
  do(assign.age.info(.))

summary(lmer(pct_play ~ age_group*facet_labels + (1|Sub_id), data = tmp))
```
```{r echo=FALSE}
rm(tmp)
```

This is not surprising given what the number of points earned already showed. But now that we are looking at a behavioral measure instead of an outcome measure we might be able to quantify constructs of interest like sensitivity to variance or sensitivity to the expected values of the machines.  

Initially I tried defining these in terms of probability of playing a machine but as I worked through this I have changed my mind about the dependent variable these changes should be defined by (or rather the coding of the dependent variable). I kept confusing myself about when playing a machine was 'good' or suggested learning. So I recoded the choices to be `correct` when a subject chooses to play a positive expected value machine and pass a negative expected value machine and `incorrect` when the reverse is true. If a subject is learning they should be learning to play the positive expected machines and to pass the others.

## Learning 

Recoding the behavior in this way gave a clearer picture of the age difference *in learning of optimal behavior* between the conditions. Specifically we can now look at how the probability of a correct choice changes for each age group in each condition across trials.

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  # ggplot(aes(trial, correct1_incorrect0))+
  ggplot(aes(scale(), correct1_incorrect0))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels)+
  theme_bw()+
  xlab("Relative trial number")+
  scale_y_continuous(breaks=c(0,1))+
  labs(col="Age group")+
  ylab('Optimal choice')+
  theme(legend.position = "bottom")
```

```{r}
tmp = machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  mutate(correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0)),
         age_group=factor(age_group, levels=c('kid', 'teen', 'adult')),
         Response = factor(Response, levels = c(0,1,2) ,labels=c('time-out', 'play', 'pass')))
```

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = tmp %>% filter(facet_labels %in% c('-10,+100')), family=binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = tmp %>% filter(facet_labels %in% c('-5,+495')), family=binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = tmp %>% filter(facet_labels %in% c('+10,-100')), family=binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = tmp %>% filter(facet_labels %in% c('+5,-495')), family=binomial))
```

```{r echo=FALSE}
rm(tmp)
```



Based on these graphs I checked for age difference in three variables:  
- The intercept: whether they are more or less likely to choose the optimal action having seen half of the trials (since trial number is centered within machine).  
- The slope: which direction and how fast the sigmoid moves in (for learning this must be positive and the larger it is the better the learning)  
- The learning index: where they are at 50% for each machine (switch point - I came up with this to see if there was a systematic change in both parameters that might be interesting. I'm not sure if it makes sense.)  

The only significant differences were in the slopes.  
- The slopes were higher for adults in both of the negative expected value conditions (t = 2.182 and t = 3.332) compared to the low variance positive expected value machine (because they are essentially 0 in the low variance positive expected condition.)  
- The slopes for kids were lower from those of adults in the high variance negative expected value condition (t = -2.370)  

```{r warning=FALSE, message = FALSE}
get_learning_coef <- function(data){
  model = glm(correct1_incorrect0 ~ trial, family = binomial(link=logit), data = data)
  b0 = coef(model)[1]
  b1 = coef(model)[2]
  learnIndex = -b0/b1                   
  return(data.frame(b0, b1, learnIndex))
}


tmp = machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) 
```

The age difference in slopes across the conditions looks as follows (again reflecting the large variability):

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  select(-b0, -learnIndex) %>%
  filter(b1<1) %>%
  group_by(age_group, facet_labels) %>%
  summarise(mean_b1 = mean(b1),
            sem_b1 = sem(b1)) %>%
  ggplot(aes(facet_labels, mean_b1, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position=position_dodge(0.9))+
  geom_errorbar(aes(ymin=mean_b1-sem_b1, ymax=mean_b1+sem_b1), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  ylab('Average slope')+
  labs(fill = 'Age group')+
  xlab('')
```

```{r}
summary(lmer(b1 ~ age_group*facet_labels + (1|Sub_id), data = tmp))
```

For reference here are the distributions and regressions on the intercepts and the learn indices as well.

```{r warning=FALSE, message = FALSE}
machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  select(-b1, -learnIndex) %>%
  ggplot(aes(b0, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_density(position = 'identity', alpha = 0.5)+
  theme_bw()+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')
```

```{r}
summary(lmer(b0 ~ age_group*facet_labels + (1|Sub_id), data = tmp))
```

```{r warning=FALSE, message = FALSE}
machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  select(-b1, -b0) %>%
  ggplot(aes(learnIndex, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_density(position = 'identity', alpha = 0.5)+
  theme_bw()+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')
```

```{r}
summary(lmer(learnIndex ~ age_group*facet_labels + (1|Sub_id), data = tmp))
```

```{r echo=FALSE}
rm(tmp)
```

## Does this correlate with BART?

Quick look at how this relates to BART data:

```{r}
adjusted.pumps <- function(subject_data){
  subject_data_adjusted = subject_data[subject_data$exploded == 0,]
  subject_pumps <- subject_data_adjusted %>% 
    group_by(trial.num) %>%
    summarise(total_pumps = sum(finished))
  out <- data.frame(mean_adjusted_pumps = mean(subject_pumps$total_pumps))
  return(out)
}
```

Increase in number of pumps with age

```{r warning=FALSE, message=FALSE}
bart_data %>%
  group_by(Sub_id) %>%
  do(adjusted.pumps(.)) %>%
  do(assign.age.info(.)) %>%
  ggplot(aes(x=calc_age, y = mean_adjusted_pumps))+
  geom_point()+
  theme_bw()+
  geom_smooth(method = "lm") +
  xlab("Age")+
  ylab("Risk taking (adjusted pumps)")
```

```{r warning=FALSE, message=FALSE}
tmp = bart_data %>%
  group_by(Sub_id) %>%
  do(adjusted.pumps(.)) %>%
  do(assign.age.info(.)) %>%
  select(Sub_id, mean_adjusted_pumps)

machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  left_join(tmp, by = 'Sub_id') %>%
  filter(b1 < 0.5, b1> (-0.5)) %>%
  ggplot(aes(mean_adjusted_pumps, b1, col = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_point()+
  geom_smooth(method = 'lm')+
  facet_wrap(~facet_labels)+
  theme_bw()+
  labs(col="Age group")+
  ylab('Individual slope')
```

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  filter(Response %in% c(1,2)) %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23,
         correct1_incorrect0 = ifelse(facet_labels %in% c('-10,+100', '-5,+495') & Response ==1,1,ifelse(facet_labels %in% c('+10,-100', '+5,-495') & Response ==2,1,0))) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  left_join(tmp, by = 'Sub_id') %>%
  group_by(facet_labels, age_group) %>%
  summarise(cor = cor.test(b1, mean_adjusted_pumps)$estimate,
            p_value = cor.test(b1, mean_adjusted_pumps)$p.value)
```
```{r echo=FALSE}
rm(tmp)
```


## Sensitivity to variance vs. expected value

How should we define these?


```{r}

get_obs_var_ev <- function(data){
  
  new_data = data
  new_data$obs_var <- NA
  new_data$obs_ev <-  NA
  
  for(i in 1:nrow(new_data)){
    if(i == 1){
      obs = 0
      obs_ev = 0
      obs_var = 0
    }
    else{
      #get all the trials until the current trial
      obs = new_data[1:i,]
      #filter only played trials; their belief should not be updated based on the trials they haven't played
      obs = obs %>% filter(Response == 1) %>% ungroup() %>% select(Points_earned)
      obs_var = var(obs)
      obs_probs =  as.numeric(prop.table(table(obs)))
      obs_rewards = as.numeric(names(prop.table(table(obs))))
      obs_ev = sum(obs_probs*obs_rewards)
    }
    new_data$obs_var[i] = obs_var
    new_data$obs_ev[i] = obs_ev
  }
  new_data$obs_var = ifelse(is.na(new_data$obs_var), 0, new_data$obs_var)
  return(new_data)
}

tmp = machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  do(get_obs_var_ev(.))%>% 
  mutate(play1_pass0 = ifelse(Response == 1, 1, 0))
```

```{r}
tmp3 = machine_game_data_clean %>% filter(Sub_id == '100003', Trial_type==1)

get_obs_var_ev(tmp3) %>% 
  select(obs_var, obs_ev, Response, Points_earned)
```

```{r}
# Do this for each subject
tmp_glm = glm(play1_pass0 ~ obs_ev, tmp,family = binomial(link=logit))

tmp$predict_glm = predict(tmp_glm)
tmp$predict_glm = with(tmp,ifelse(predict_glm>0.5,1,0))

sum(tmp$play1_pass0 == tmp$predict_glm)/nrow(tmp)
###########
tmp %>%
  ggplot(aes(obs_ev, obs_var)) +
  geom_point()+
  facet_wrap(~facet_labels, scales='free')+
  theme_bw()
```

```{r}
# This model is not really interesting
# summary(glmer(play1_pass0 ~ scale(obs_var)+scale(obs_ev)+age_group+facet_labels+(1|Sub_id), 
#       family = binomial(link=logit), data = tmp))

#Convergence problems begin even here
# summary(glmer(play1_pass0 ~ scale(obs_var)+scale(obs_ev)+age_group+facet_labels+
#                 scale(obs_var):age_group+
#                 scale(obs_ev):age_group+
#                 (1|Sub_id), 
#       family = binomial(link=logit), data = tmp))

# The 3 way interactions (age*facet*var and age*facet*ev) are of interest here
# BUT This seems to take forever; won't converge
# glmer(play1_pass0 ~ scale(obs_var)+scale(obs_ev)+age_group+facet_labels+
#         scale(obs_ev):age_group:facet_labels+
#         scale(obs_var):age_group:facet_labels+(1|Sub_id), 
#       family = binomial(link=logit), data = tmp)

# Estimate var and ev parameters for each subject in each condition separately and compare those
# This is very crude but just trying
```

```{r warning=FALSE, message=FALSE}
tmp %>%
  group_by(Sub_id, facet_labels) %>%
  ggplot(aes(obs_ev, play1_pass0))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels, scales='free')+
  theme_bw()+
  xlab("EV of played trials")+
  scale_y_continuous(breaks=c(0,1))+
  labs(col="Age group")+
  ylab('Play vs. pass')
```

```{r warning=FALSE, message=FALSE}
tmp %>%
  group_by(Sub_id, facet_labels) %>%
  ggplot(aes(obs_var, play1_pass0))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels, scales='free')+
  theme_bw()+
  xlab("Variance of played trials")+
  scale_y_continuous(breaks=c(0,1))+
  labs(col="Age group")+
  ylab('Play vs. pass')
```

```{r warning=FALSE, message=FALSE}
tmp %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = (1:n())-23) %>%
  ggplot(aes(trial, obs_var))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'lm', se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'lm', se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels, scales='free')+
  theme_bw()+
  xlab("Relative trial number")+
  labs(col="Age group")+
  ylab('Observed variance')
```

```{r warning=FALSE, message=FALSE}
tmp %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = 1:n()) %>%
  ggplot(aes(trial, obs_ev))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'lm', se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'lm', se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels, scales='free')+
  theme_bw()+
  xlab("Relative trial number")+
  labs(col="Age group")+
  ylab('Observed expected value')
```

```{r}
summary(tmp$obs_ev)
summary(tmp$obs_var)
```

```{r}
tmp2 <- tmp %>% filter(Sub_id == '409381', Trial_type==1) %>% mutate(trial = 1:n())

summary(glm(play1_pass0 ~ trial + obs_var + obs_var:trial + obs_ev + obs_ev:trial, data = tmp2, family = binomial(link = logit)))
```

```{r}
get_sensitivity <- function(data){
  betas = as.data.frame(coef(glm(play1_pass0 ~ trial + scale(obs_var, center=F) + scale(obs_var, center=F):trial + scale(obs_ev, center=F) + scale(obs_ev, center=F):trial, data = data, family = binomial(link = logit)))) 
  betas$key = row.names(betas)
  row.names(betas) = c(1:nrow(betas))
  names(betas)[1] = c('value')
  return(betas %>% spread(key, value))
}

betas = tmp %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = 1:n()) %>%
  do(get_sensitivity(.)) %>%
  do(assign.age.info(.))

tmp %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(trial = 1:n()) %>%
  do(get_sensitivity(.))
```

```{r}
names(betas) = gsub("\\(|\\)", "", names(betas))

betas %>%
  select(-calc_age, -Intercept) %>%
  gather(key, value, -Sub_id, -facet_labels, -age_group) %>%
  group_by(age_group, facet_labels, key) %>%
  summarise(mean_val=mean(value, na.rm=T),
            sem_val = sem(value)) %>%
  ggplot(aes(key, mean_val, fill = factor(age_group, levels=c('kid', 'teen', 'adult'))))+
  geom_bar(stat='identity', position=position_dodge(0.9))+
  geom_errorbar(aes(ymin=mean_val-sem_val, ymax=mean_val+sem_val), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('')+
  ylab('Parameter estimate')+
  labs(fill = 'Age group')+
  facet_wrap(~facet_labels)
```

```{r}
summary(lm(obs_ev ~ age_group*facet_labels, data = betas))
```

```{r}
summary(lm(obs_var ~ age_group*facet_labels, data = betas))
```

-- optimal choice per trial
-- how does this relationship change across learning