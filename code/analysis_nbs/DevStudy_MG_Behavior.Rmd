---
title: "Developmental differences in learningfrom large but rare losses"
output: 
html_document:
toc: true
toc_depts: 2
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
source('/Users/zeynepenkavi/Dropbox/PoldrackLab/DevStudy_Analyses/code/workspace_scripts/DevStudy_workspace.R')
```

This notebook contains exploratory analyses of behavioral data collected to investigate the relationship between risk taking behavior and probabilistic learning.  

The sample consists of three age groups: kids, teens and adults and we hypothesize that sensitivity to learn from high variance feedback improves with age (and this is related to better risky decisions).  

Subjects completed a probabilistic learning task in the scanner, a risky decision making task (BART) outside the scanner and numerous questionnaires. The focus of this notebook is on the first task.  

The plan of analysis is to establish that adults are more sensitive to high variance feedback in the probabilistic learning task and relate this (modeled) sensitivity to behavior both in BART and other self-reported risky behaviors. Details of correlations are found [here](https://zenkavi.github.io/DevStudy_Analyses/output/reports/DevStudy_Other_Behavior.nb.html)

# Sample info

First let's get a sense of the sample. Here is how many subjects we have who have complete datasets for the probabilistic learning task and their age break downs.

```{r sample_info, warning=FALSE}
machine_game_data_clean %>% 
  group_by(age_group) %>%
  summarise(min_age = min(calc_age),
            mean_age = mean(calc_age),
            sd_age = sd(calc_age),
            max_age = max(calc_age),
            n = ceiling(n()/180))
```

# Performance in RL task

This task is a modified Iowa Gambling Task. Subjects are presented with a fractal in each trial. The fractals represent different machines (single-armed bandits). Subjects choose to play or pass in each trial. Each machine yields a probabilistic reward. There are four machines in total. Two with positive and two with negative expected value. One of each of these machines has a low variance reward schedule while the other has a high variance reward schedule. 

- One machine gives \$5 90% of the time and -\$495 %10 of the time  
- One machine gives -\$5 90% of the time and \$495 %10 of the time  
- One machine gives \$10 50% of the time and -$100 %50 of the time  
- One machine gives -\$10 50% of the time and $100 %50 of the time  

## Points earned

Performance in this task can be assessed by looking at the total number of points subjects make at the end of task. The following graph shows that adults collect more points in this task compared to kids.

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group) %>%
  summarise(mean_points = mean(total_points),
            sem_points = sem(total_points)) %>%
  ggplot(aes(age_group, mean_points))+
  geom_bar(stat='identity', position = position_dodge((0.9)))+
  geom_errorbar(aes(ymin=mean_points-sem_points, ymax=mean_points+sem_points), position = position_dodge(0.9), width=0.25)+
  theme_bw()+
  xlab('Machine')+
  ylab('Mean points')+
  labs(fill='Age group')

```

This difference is statistically significant: adults earn more points compared to the kids.

```{r}
tmp = machine_game_data_clean %>%
  group_by(Sub_id) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.))

summary(lm(total_points~age_group, data=tmp))
```

On average each group earned:

```{r}
tmp %>% 
  group_by(age_group) %>% 
  summarise(mean_points = mean(total_points))
```

```{r echo=FALSE}
rm(tmp)
```

Since we are interested in the age differences between sensitivity to different feedback schedules, **we should show that this difference in performance exists especially for the high variance feedback condition(s)**. Here is the plot of performance (total points earned) broken down by conditions.

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, facet_labels) %>%
  summarise(mean_points = mean(total_points),
            sem_points = sem(total_points)) %>%
  ggplot(aes(facet_labels, mean_points, fill=age_group))+
  geom_bar(stat='identity', position = position_dodge((0.9)))+
  geom_errorbar(aes(ymin=mean_points-sem_points, ymax=mean_points+sem_points), position = position_dodge(0.9), width=0.25)+
  # theme_bw()+
  xlab('Machine')+
  ylab('Mean points')+
  labs(fill='Age group')

ggsave("Points_earned.jpeg", device = "jpeg", path = fig_path, width = 7, height = 5, units = "in", dpi = 450)
```

Running separate models for positive and negative EV machines for ease of interpretation.

```{r}
tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(total_points = sum(Points_earned)) %>%
  do(assign.age.info(.))
```

In the positive EV machines there is a main effect for the high variance machine. Subjects earn fewer points in the high variance condition compared to the low variance condition. There are no age differences.

```{r}
summary(lm(total_points ~ age_group*facet_labels, data = tmp %>% filter(facet_labels %in% c("-10,+100", "-5,+495"))))
```

In the negative EV machines there is again a main effect for the high variance machine: Everyone losses fewer points in the low variance condition. There is also a main effect for adults: Adults perform better than kids for both negative EV machines.

```{r}
summary(lm(total_points ~ age_group*facet_labels, data = tmp %>% filter(facet_labels %in% c("+10,-100", "+5,-495"))))
```

```{r echo=FALSE}
rm(tmp)
```

**So the age diffence in performance is driven by difference in performance in negative EV machines. The question is what difference in behavior in these conditions is leading to this difference in performance?**    

To anticipate possible cognitive processes that will be parameterized in RL models differences can lie in: how quickly the groups learn the probabilities, how much weight they put on the outcomes and/or how much like an optimal agent they behave.

## Proportion of playing

The first thing we can look at is how often subjects play versus pass. It's hard to see any age differences when we just look at frequency of overall playing as below.   

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, Response) %>%
  tally %>%
  group_by(Sub_id) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, Response) %>%
  dplyr::summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = age_group))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  theme_bw()+
  ylab('Percentage of trials')+
  labs(fill = 'Age group')
```

It is also not immediately apparent how to translate this to better performance/learning in this task but one way to think about it: If people learned perfectly they should play half of the time (always for the positive expected value trial and never for the negative expected value trials). The fact that all play proportions are above 50% suggests that nobody learns perfectly and that adults might be closest to it. But this is very crude and a better way to look at it would be to see   

1. how this depends on the different machines and   
2. how it changes throughout the task.

To get a better sense of overall behavior in different contingency states we break this proportion of playing down by machines.

Now we can see age differences in playing frequency in different conditions, particularly in the negative expected value machines (bottom row).

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct=(100*n)/sum(n)) %>%
  do(assign.age.info(.)) %>%
  group_by(age_group, facet_labels, Response) %>%
 summarise(mean_pct = mean(pct),
            sem_pct = sem(pct)) %>%
  ggplot(aes(Response, mean_pct, fill = age_group))+
  geom_bar(stat='identity', position = position_dodge(0.9))+
  geom_errorbar(aes(ymin = mean_pct - sem_pct, ymax = mean_pct + sem_pct), position = position_dodge(width = 0.9), width=0.25)+
  ylab('Percentage of trials')+
  facet_wrap(~facet_labels)+
  labs(fill = 'Age group')

ggsave("Prop_played.jpeg", device = "jpeg", path = fig_path, width = 8, height = 5, units = "in", dpi = 450)
```

The differences in points earned map directly on to proportion of choosing to play each machine:  

- Adults play less than kids for both negative EV machines. 
- Everyone plays the high var positive EV machine less than the low var positive EV machine.
- Everyone plays the low var negative EV machines less than the low var positive EV machine.

```{r}
tmp <- machine_game_data_clean %>%
  group_by(Sub_id, facet_labels, Response) %>%
  tally %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(pct_play=(100*n)/sum(n)) %>%
  filter(Response == 'play') %>%
  do(assign.age.info(.))

summary(lmer(pct_play ~ age_group*facet_labels + (1|Sub_id), data = tmp))
```
```{r echo=FALSE}
rm(tmp)
```

This is not surprising given what the number of points earned already showed. But now that we are looking at a behavioral measure instead of an outcome measure we might be able to quantify constructs of interest like sensitivity to variance or sensitivity to the expected values of the machines.  

As a first step to translate raw playing behavior to learning I recoded the choices to be `correct` when a subject chooses to play a positive expected value machine and pass a negative expected value machine and `incorrect` when the reverse is true. If a subject is learning they should be learning to play the positive expected machines and to pass the others.

## Learning 

Recoding the behavior in this way gave a clearer picture of the age difference *in learning of optimal behavior* between the conditions. Specifically we can now look at how the probability of a correct choice changes for each age group in each condition across trials.

```{r warning=FALSE, message=FALSE}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  mutate(rel_tm = 1:n()) %>%
  # ggplot(aes(scale(Trial_number), correct1_incorrect0))+
    ggplot(aes(rel_tm, correct1_incorrect0))+
  geom_line(aes(group = Sub_id, col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=0.2)+
  geom_line(aes(col= factor(age_group, levels=c('kid', 'teen', 'adult'))),stat='smooth', method = 'glm', method.args = list(family = "binomial"), se = FALSE, alpha=1, size=2)+
  facet_wrap(~facet_labels)+
  theme_bw()+
  # xlab("Relative trial number")+
  xlab("Trial number")+
  scale_y_continuous(breaks=c(0,1))+
  labs(col="Age group")+
  ylab('Correct choice')+
  theme(legend.position = "bottom",
        panel.grid = element_blank())

ggsave("Learning.jpeg", device = "jpeg", path = fig_path, width = 8, height = 5, units = "in", dpi = 450)
```

There is no significant change in behavior across time for the positive EV machines while there is for the negative EV machines. **If the initial behavior is exploratory playing this pattern would indicate 'learning' occuring for both types of machines.**

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean %>% filter(facet_labels %in% c('-10,+100', '-5,+495')), family=binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean %>% filter(facet_labels %in% c('+10,-100', '+5,-495')), family=binomial))
```

Looking at learning effects separately for each machine:

Adults are more likely to make correct decisions in low var positive EV machine.

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean %>% filter(facet_labels %in% c('-10,+100')), family=binomial))
```

The probability of making a correct response for the high var positive EV machine doesn't change for adults or kids but increases for teens across trials.

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean %>% filter(facet_labels %in% c('-5,+495')), family=binomial))
```

All groups show improvement across trials for the low var negative EV machine but adults learn faster than kids and teens.

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean %>% filter(facet_labels %in% c('+10,-100')), family=binomial))
```

Kids don't show learning across trials for the high var negative EV machine but adults and teens do. 

```{r}
summary(glmer(correct1_incorrect0 ~ age_group*scale(Trial_number)+(1|Sub_id), data = machine_game_data_clean%>% filter(facet_labels %in% c('+5,-495')), family=binomial))
```

### Grouping by learning

The thin lines in the above plot denote individual subjects. They vary largely from each other including within age groups. This highlights the amount of individual variability in learning behavior. Therefore, another and perhaps even more useful group classification in understanding behavioral differences for this sample is between “learner” and “non-learners.” These groups are operationally defined as subjects who have a positive or negative slope to their sigmoid curves in the above graph. The sign of the slope indicates the sigmoids direction while its magnitude the speed with which the curve towards the boundary. Thus, a positive slope implies that a subject was more likely to make a “correct” choice later in the task than they were earlier.

```{r warning=FALSE, message = FALSE}
get_learning_coef <- function(data){
  model = glm(correct1_incorrect0 ~ scale(Trial_number), family = binomial(link=logit), data = data)
  b0 = coef(model)[1]
  b1 = coef(model)[2]
  learnIndex = -b0/b1                   
  return(data.frame(b0, b1, learnIndex))
}
```

Defined in this manner we find 

```{r warning=FALSE, message=FALSE}
tmp = machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  do(get_learning_coef(.)) %>%
  do(assign.age.info(.)) %>%
  mutate(learner = ifelse(b1>0,1,0))

with(tmp, table(learner, facet_labels, age_group))
```

```{r}
non_learners = tmp %>%
  #ONLY THE nEV machines
  filter(facet_labels %in% c("+5,-495", "+10,-100")) %>%
  filter(learner == 0)

non_learners = unique(non_learners$Sub_id)
#non_learners

learner_info = data.frame(Sub_id = unique(machine_game_data_clean$Sub_id))

learner_info = learner_info %>%
  mutate(learner = ifelse(Sub_id %in% non_learners == FALSE, 1, 0),
         non_learner = ifelse(Sub_id %in% non_learners, 1, 0),
         Sub_id = paste0('sub-', Sub_id)) 

#write.csv(learner_info, '/Users/zeynepenkavi/Dropbox/PoldrackLab/DevStudy_ServerScripts/nistats/level_3/learner_info.csv', row.names = FALSE)

data.frame(Sub_id = unique(machine_game_data_clean$Sub_id)) %>%
  mutate(learner = ifelse(Sub_id %in% non_learners == FALSE, 1, 0),
         non_learner = ifelse(Sub_id %in% non_learners, 1, 0),
         age_group = ifelse(Sub_id<200000, "kid", ifelse(Sub_id>200000 & Sub_id<400000, "teen", "adult")),
         age_group = factor(age_group, levels = c("kid", "teen", "adult"))) %>%
  group_by(age_group)  %>%
  summarise(total_learners = sum(learner),
            total_non_learners = sum(non_learner))
```

### Variance vs. EV effects on learning

A subject-level measure of learning (the slope of the sigmoids) allows us to compare the effect of the two varying attributes (EV and variance) on learning. To do so we compared the difference in slopes between the two conditions of each attribute and computed the effect of EV and variance for each subject.

```{r}
ev_var_effect = tmp %>% 
  select(Sub_id, b1, age_group, facet_labels) %>%
  #some adults have too large slopes (making the below effects unnecessarily large)
  filter(b1<10) %>%
  spread(facet_labels, b1) %>%
  mutate(ev_effect = (`+10,-100`+ `+5,-495`) - (`-10,+100`+ `-5,+495`), #row difference,
         var_effect = (`+5,-495` + `-5,+495`) - (`+10,-100`+ `-10,+100`) #col difference
         ) %>%
  select(Sub_id, age_group, ev_effect, var_effect) %>%
  gather(key, value, -Sub_id, -age_group) %>%
  mutate(learner = ifelse(Sub_id %in% non_learners, 0, 1))
```

A large ev effect suggests larger slope for negative ev machines compared to positive machines. 
A large var effect larger slope for high var machines than low var machines.

```{r}
ev_var_effect %>%
  ggplot(aes(age_group, value, fill=age_group))+
  geom_boxplot()+
  facet_wrap(~key)+
  theme(legend.position = "none")
```

Adults show both larger EV and var effects compared to kids. But var vs. ev effect does not differ from each other.

```{r}
summary(lm(value~key*age_group,ev_var_effect))
```

Correspondingly learners show larger effects of both variance and EV compared to non-learners. Again EV and var effects do not differ from each other.

```{r}
summary(lm(value~key*learner,ev_var_effect))
```

## Additional behavioral patterns

Though I focus on learning behavior and specifically difference in learning for the high variance negative EV machine there are other possible behavioral patterns that might also differ between the age groups. Here I list some examples.

### Initial exploration

Do people 'explore' the first 10 trials where the reward probabilities for each machine are presented?

They explore less when they encounter a loss early on. In the high var pos EV machine they get 4 (small) losses in a row; in the low var negative EV machine they get a moderate loss in the first trial.

```{r eval=FALSE}
machine_game_data_clean %>% 
  group_by(Sub_id, facet_labels) %>%
  slice(1:10) %>%
  summarise(num_explored = sum(ifelse(Response == "play", 1,0))) %>%
  do(assign.age.info(.)) %>%
  ungroup() %>%
  group_by(age_group, facet_labels) %>%
  summarise(mean_num_explored = mean(num_explored/10*100),
            sem_num_explored = sem(num_explored/10*100)) %>%
  ggplot(aes(facet_labels, mean_num_explored, fill = age_group))+
  geom_bar(stat="identity",position = position_dodge(0.9))+
  geom_errorbar(aes(ymax = mean_num_explored+sem_num_explored, ymin = mean_num_explored-sem_num_explored), position = position_dodge(width = 0.9), width=0.25)+
  theme(legend.title = element_blank())+
  ylab("Percentage of exploration")+
  xlab("")
```

```{r}
tmp = machine_game_data_clean %>% 
  group_by(Sub_id, facet_labels) %>%
  slice(1:10) %>%
  summarise(num_explored = sum(ifelse(Response == "play", 1,0))) %>%
  mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner")) 
tmp %>%
  ungroup() %>%
  group_by(learner, facet_labels) %>%
  summarise(mean_num_explored = mean(num_explored/10*100),
            sem_num_explored = sem(num_explored/10*100)) %>%
  ggplot(aes(facet_labels, mean_num_explored, fill = learner))+
  geom_bar(stat="identity",position = position_dodge(0.9))+
  geom_errorbar(aes(ymax = mean_num_explored+sem_num_explored, ymin = mean_num_explored-sem_num_explored), position = position_dodge(width = 0.9), width=0.25)+
  theme(legend.title = element_blank())+
  ylab("Percentage of exploration")+
  xlab("")
```

lVAR pEV is explored more in the first 10 trials compared to the other machines and even more so for learners compared to non-learners.

```{r}
summary(lm(num_explored ~ learner*facet_labels, tmp))
```

### Memory effect

How does performance change depending on the delay between the last time a machine was played?  

Can we think of this as a 'memory effect'? The more trials since the last time you have played a machine, the more forgetting/interference? 

We find a negative effect of the play delay only for hVAR pEV. Perhaps the large reward participants experience lead to a more salient representation than the more frequent small losses. In contrast, both nEV are more likely to be correct the longer the delay  possibly by allowing more time for integration.

```{r warning=FALSE, message=FALSE}
tmp = machine_game_data_clean %>%
  group_by(Sub_id) %>%
  mutate(played_trial_number = ifelse(Response == "play", Trial_number, NA)) %>%
  mutate(played_trial_number = na.locf(played_trial_number, na.rm=F)) %>%
  filter(Trial_number > 1) %>%
  mutate(trials_since_last_played = Trial_number - lag(played_trial_number)) %>%
  mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner")) 
tmp %>%
  ggplot(aes(trials_since_last_played, correct1_incorrect0, col = learner))+
  geom_line(stat='smooth', method = 'glm', method.args = list(family = "binomial"), alpha=1, size=2)+
  facet_wrap(~facet_labels)+
  theme(legend.title = element_blank())+
  xlab("Trials since last played")+
  ylab("Correct")+
  scale_y_continuous(breaks=c(0,1))
  
```

```{r}
summary(glmer(correct1_incorrect0 ~ trials_since_last_played*learner+(1|Sub_id),tmp %>% filter(facet_labels == "-10,+100"), family = binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ trials_since_last_played*learner+(1|Sub_id),tmp %>% filter(facet_labels == "-5,+495"), family = binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ trials_since_last_played*learner+(1|Sub_id),tmp %>% filter(facet_labels == "+10,-100"), family = binomial))
```

```{r}
summary(glmer(correct1_incorrect0 ~ trials_since_last_played*learner+(1|Sub_id),tmp %>% filter(facet_labels == "+5,-495"), family = binomial))
```


### Post-loss behavior

If subjects are sensitive to losses and learning something about the machines in a way that overweights their most recent experience with the machine one sanity check is to compare how many trials it takes subjects to play a machine again after a loss versus a gain. Presumably the former would be higher than the latter. One might hesitate to play a machine again after a loss but be more likely to play it after a gain.

```{r}
count.postoutcome.trials <- function(subject_data){
  
  loss_trials = which(subject_data$Points_earned<0)
  
  gain_trials = which(subject_data$Points_earned>0)
  
  play_trials= which(subject_data$Response == "play")
  
  post_loss_trials = play_trials[which(play_trials %in% loss_trials)+1]
  
  post_gain_trials = play_trials[which(play_trials %in% gain_trials)+1]
  
  num_trials_post_loss = post_loss_trials - loss_trials
  
  num_trials_post_gain = post_gain_trials - gain_trials
  
  if(length(num_trials_post_gain)>length(num_trials_post_loss)){
    num_trials_post_loss <- c(num_trials_post_loss, rep(NA, length(num_trials_post_gain) - length(num_trials_post_loss)))
  }
  else if(length(num_trials_post_gain)<length(num_trials_post_loss)){
    num_trials_post_gain <- c(num_trials_post_gain, rep(NA, length(num_trials_post_loss) - length(num_trials_post_gain)))
  }
  
  return(data.frame(num_trials_post_loss = num_trials_post_loss, num_trials_post_gain = num_trials_post_gain))
}
```

The plot below shows the average number of trials it takes a subject to play a given machine after experiencing a loss or a gain.   

For everyone and for every machine the average number of trials it takes a subject to play following a loss is higher than the average number of trials it take them to play following a gain. This suggests that subjects are responding to outcomes in a way overweights their most recent experience with the machine.   

The fact that the probability of playing following a loss depends on machine type suggests that subjects learn machine-specifically and mitigates concern about cross-talk across them.

```{r}
tmp = machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  do(count.postoutcome.trials(.))  %>%
  do(assign.age.info(.)) %>%
  ungroup() %>%
  select(facet_labels, age_group, num_trials_post_loss, num_trials_post_gain, Sub_id) %>%
  gather(key, value, -facet_labels, -age_group, -Sub_id) %>%
  mutate(key = gsub("num_trials_post_", "", key)) %>%
   mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner"))
```

```{r}
tmp %>%
  group_by(facet_labels, learner, key) %>%
  summarise(mean_post = mean(value, na.rm=T),
            sem_post = sem(value)) %>%
  ggplot(aes(learner, mean_post, fill=key, key=learner))+
  # geom_point(size=2)+
  geom_bar(stat="identity",position = position_dodge(width=0.9), width=0.7)+
  geom_errorbar(aes(ymin = mean_post-sem_post, ymax = mean_post+sem_post), width=0, position = position_dodge(width=0.9))+
  facet_wrap(~facet_labels)+
  ylab("Number of trials until next play")+
  xlab("")+
  theme(legend.title = element_blank())+
  guides(color=FALSE)
```

Everyone takes longer to play after a loss than a gain. This is even more prominent for nEV.

```{r}
summary(lm(value~key*facet_labels,tmp))
```

And for learners.

```{r}
summary(lm(value~key*learner,tmp))
```

Does how long a participant thinks before playing affect whether they play after experiencing a loss? Yes. Particularly for learners there is a reverse speed-accuracy tradeoff.

```{r}
tmp = machine_game_data_clean %>%
  mutate(losstrial = ifelse(Points_earned<0,1,0),
         postloss = lag(losstrial),
         postloss_play1_pass0 = ifelse(postloss == 1 & Response == "play",1, ifelse(postloss==1 & Response == "pass", 0, NA)),
         lastlossamt = lag(Points_earned)) %>%
  filter(postloss==1) %>%
   mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner"))
```

```{r}
tmp %>%
  ggplot(aes(Reaction_time, correct1_incorrect0))+
  geom_smooth(aes(col=learner), method='glm', method.args = list(family = "binomial"))+
  facet_wrap(~facet_labels)+
  scale_y_continuous(breaks=c(0,1))+
  theme(legend.title = element_blank())+
  xlab("RT")+
  ylab("Probability of correct following a loss")
```

```{r}
summary(glmer(correct1_incorrect0 ~ scale(Reaction_time)*learner+(1|Sub_id), tmp, family = binomial))
```

### Response time differences

```{r}
machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(mean_log_rt = mean(log(Reaction_time)),
            sem_log_rt = sem(log(Reaction_time))) %>%
  # do(assign.age.info(.)) %>%
  mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner"))%>%
  ggplot(aes(learner, mean_log_rt))+
  geom_boxplot(aes(fill=learner))+
  facet_grid(~facet_labels)+
  theme(legend.position = "none")+
  ylab("Mean Log RT")+
  xlab("")
```

Learners are faster than non-learners in general.
Interaction?

```{r}
summary(lmer(log(Reaction_time) ~ learner*facet_labels +(1|Sub_id), data = machine_game_data_clean %>% mutate(learner = ifelse(Sub_id %in% non_learners, "non-learner","learner"))))
```

## RL modeling

Details of model comparison can be found in a separate [notebook](http://zenkavi.github.io/DevStudy_Analyses/output/reports/Comp_RL.nb.html).