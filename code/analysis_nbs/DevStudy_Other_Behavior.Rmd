---
title: "Developmental differences learning from large lossses"
output: 
html_document:
toc: true
toc_depts: 2
---

In addition to the RL task, this dataset contains self-reported 'real-world' risk behaviors, several impulsivity surveys and BART. One question of interest was whether any of the measures predicted the 'real-world' risk behaviors. This report looks into that question.

## DV: Real-world risk dimensions

Real-world risk was measured using two questionnaires with a total of 63 items. Not all of these items had sufficient variance to be useful so we filtered out those that could not be transformed successfully to have skewness <2 and applied hierarchical clustering on the remaining items. 

Here is the list of items that were skewed and could not transformed successfully.

```{r echo=FALSE, message=FALSE, warning=FALSE}
source('/Users/ally/Desktop/Lab/DevStudy_Analyses/code/workspace_scripts/DevStudy_workspace.R')
```

The remaining 29 items were entered into a hierarchical clustering analysis. Here is the tree structure of the remaining items

```{r warning=FALSE, message=FALSE}
library(ggdendro)

try$labels = gsub(".logTr","",try$labels)
try$labels = gsub("_.*","",try$labels)

input_path = '/Users/ally/Desktop/Lab/DevStudy_Analyses/input/'
survey_questions = read.csv(paste0(input_path,"survey_questions.csv"))

tmp = data.frame(label=try$labels) %>%
  left_join(survey_questions, by="label")

tmp$question = gsub("\\.", " ", tmp$question)
tmp$question = gsub("^\\d+|\\d+$", "", tmp$question) 
try$labels = tmp$question
```

```{r message=FALSE, warning=FALSE}
# ggdendrogram(try, rotate=TRUE)+
#   theme(panel.border = element_blank())

p = segment(dendro_data(try)) %>%
  mutate(seg_col = ifelse(yend<1.76 & xend < 8, 1, ifelse(yend<1.76 & xend>7 & xend<18, 2, ifelse(yend<1.76 & xend>17 & xend < 22, 3, ifelse(yend<1.76 & xend>21,4,5))))) %>%
  ggplot(aes(x = label))+
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend, col=factor(seg_col)),alpha = 1, size=1.5)+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(), 
        legend.position = "none",
        axis.text.y = element_text(size=14))+
  scale_x_discrete(limits = (label(dendro_data(try))$label))+
  scale_color_manual(values = c(cbbPalette[1:4], "grey"))+
  coord_flip()+
  xlab("")+
  ylab("")

ggsave("Risk_tree.jpeg", device = "jpeg", path = fig_path, width = 12, height = 10, units = "in", dpi = 450)
```

```{r echo=FALSE, out.width='100%'}
fig_name = 'Risk_tree.jpeg'

knitr::include_graphics(paste0(fig_path, fig_name))
```

The code for factorizing the risk items can be found [here](https://github.com/zenkavi/DevStudy_Analyses/blob/master/code/workspace_scripts/questionnaire_data.R)

The four 'real-world risk' factors are distributed as follow

```{r message=FALSE, warning=FALSE}
q_data %>%
  select(contains("scores")) %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram()+
  facet_wrap(~key, scales = "free")
```

## IV: All behavioral measures

```{r}
machine_game_summary = machine_game_data_clean %>%
  group_by(Sub_id, facet_labels) %>%
  summarise(sum_correct = sum(correct1_incorrect0),
            mg_mean_rt = mean(Reaction_time, na.rm=T),
            mg_sd_rt = sd(Reaction_time)) %>%
  gather(key, value, -Sub_id, -facet_labels) %>%
  unite(temp, facet_labels, key) %>%
  spread(temp, value)

best_models = c("Fit_alpha_neg-alpha_pos-beta-exp_Fix_lossave_","Fit_alpha_neg-alpha_pos-beta-exp_neg-exp_pos_Fix_lossave_","Fit_alpha-beta-exp_neg-exp_pos_Fix_lossave_")

m1_data = best_sub_pars %>%
  filter(model %in% best_models[1]) %>%
  select(sub_id, xopt_alpha_neg, xopt_alpha_pos, xopt_beta, xopt_exp) %>%
  rename_all(function(x) paste0("m1_", x)) %>%
  rename(Sub_id = m1_sub_id)

m2_data = best_sub_pars %>%
  filter(model %in% best_models[2]) %>%
  select(sub_id, xopt_alpha_neg, xopt_alpha_pos, xopt_beta, xopt_exp_neg, xopt_exp_pos) %>%
  rename_all(function(x) paste0("m2_", x)) %>%
  rename(Sub_id = m2_sub_id)

m3_data = best_sub_pars %>%
  filter(model %in% best_models[3]) %>%
  select(sub_id, xopt_alpha, xopt_beta, xopt_exp_neg, xopt_exp_pos) %>%
  rename_all(function(x) paste0("m3_", x)) %>%
  rename(Sub_id = m3_sub_id)

all_behavioral_data = machine_game_summary %>%
  left_join(bart_adjusted_pumps %>% select(-age_group), by="Sub_id") %>%
  left_join(q_data %>% rename(Sub_id = id), by="Sub_id") %>%
  left_join(m1_data, by = "Sub_id") %>%
  left_join(m2_data, by = "Sub_id") %>%
  left_join(m3_data, by = "Sub_id") %>%
  ungroup()%>%
  select(-Sub_id)

all_behavioral_data
```

Calculating relationships between all behavioral measures controlling for age and intelligence

```{r warning=FALSE, message=FALSE}
cor_df = data.frame(var1=NA, var2=NA, b_x=NA, p_x=NA, b_age = NA, p_age = NA, b_vocab_raw=NA, p_vocab_raw=NA, b_mr_raw=NA, p_mr_raw=NA)

#Removing two outlier 
all_behavioral_data = all_behavioral_data %>%
  filter(m3_xopt_beta<3)
all_behavioral_data_clean = transform_remove_skew(all_behavioral_data, columns=names(all_behavioral_data), drop=T, threshold=2)
dvs = names(all_behavioral_data_clean %>% select(-calc_age, -vocab_raw, -mr_raw.logTr, -gender))
for(i in 1:(length(dvs)-1)){
  x = all_behavioral_data_clean %>% pull(dvs[i])
  rem_dvs = dvs[-c(1:i)]
  
  for(j in 1:length(rem_dvs)){
    y = all_behavioral_data_clean %>% pull(rem_dvs[j])
    
    m = lm(scale(y) ~ scale(x) + all_behavioral_data_clean$calc_age+ all_behavioral_data_clean$vocab_raw+ all_behavioral_data_clean$mr_raw.logTr)
    
    cor_df = rbind(cor_df, c(var1=dvs[i], 
                             var2=rem_dvs[j], 
                             b_x=coefficients(m)["scale(x)"], 
                             p_x= coef(summary(m))["scale(x)","Pr(>|t|)"], 
                             b_age=coefficients(m)["all_behavioral_data_clean$calc_age"], 
                             p_age= coef(summary(m))["all_behavioral_data_clean$calc_age","Pr(>|t|)"], 
                          b_vocab_raw=coefficients(m)["all_behavioral_data_clean$vocab_raw"],
                          p_vocab_raw= coef(summary(m))["all_behavioral_data_clean$vocab_raw","Pr(>|t|)"],
                          b_mr_raw=coefficients(m)["all_behavioral_data_clean$mr_raw.logTr"],
                          p_mr_raw= coef(summary(m))["all_behavioral_data_clean$mr_raw.logTr","Pr(>|t|)"]))
  }
}
rm(dvs, x, y, m, i, j)
```

## All correlations

```{r}
cor_df = cor_df %>%
  filter(!is.na(var1)) %>%
  mutate(b_x = as.numeric(b_x),
         p_x = as.numeric(p_x),
         b_age = as.numeric(b_age),
         p_age = as.numeric(p_age),
         b_vocab_raw = as.numeric(b_vocab_raw),
         p_vocab_raw = as.numeric(p_vocab_raw),
         b_mr_raw = as.numeric(b_mr_raw),
         p_mr_raw = as.numeric(p_mr_raw))

cor_df %>%
  arrange(p_x) %>%
  datatable() %>%
  formatRound(columns=c('b_x', 'p_x', 'b_age', 'p_age', 'b_vocab_raw', 'p_vocab_raw', 'b_mr_raw', 'p_mr_raw'), digits=3)
```

### All "significant" correlations relating to "real-world risky behavior"

```{r}
cor_df %>%
  filter(p_x<0.05)%>%
  filter(grepl("scores", var1) | grepl("scores", var2)) %>%
  mutate(drp = ifelse(grepl("scores", var1) & grepl("scores", var2), 1, 0)) %>%
  filter(drp == 0) %>%
  select(-drp)%>%
  arrange(p_x) %>%
  datatable() %>%
  formatRound(columns=c('b_x', 'p_x', 'b_age', 'p_age', 'b_vocab_raw', 'p_vocab_raw', 'b_mr_raw', 'p_mr_raw'), digits=3)
```

### Significant correlations that survive multiple comparisons

```{r}
cor_df%>%
  mutate(adj_p_x = p.adjust(p_x, method="fdr"))%>%
  filter(adj_p_x<0.05) %>%
  filter(grepl("scores", var1) | grepl("scores", var2)) %>%
  mutate(drp = ifelse(grepl("scores", var1) & grepl("scores", var2), 1, 0)) %>%
  filter(drp == 0) %>%
  select(-drp)%>%
  arrange(adj_p_x) %>%
  datatable() %>%
  formatRound(columns=c('b_x', 'p_x', 'b_age', 'p_age', 'b_vocab_raw', 'p_vocab_raw', 'b_mr_raw', 'p_mr_raw', 'adj_p_x'), digits=3)
```
